{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a288ec",
   "metadata": {
    "id": "chcr1ibHHbS_",
    "papermill": {
     "duration": 0.011865,
     "end_time": "2024-04-23T18:40:55.713949",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.702084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identifying PII in Student Essays\n",
    "## Authored by: Pratik Chaudhari, Cody Ledford, Manu Achar\n",
    "## Project Summary\n",
    "The Kaggle Competition we are participating in is the [PII Data Detection hosted by The Learning Agency Lab](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview). The goal of this competition is to develop a model that detects sensitive personally identifiable information (PII) in student writing. This is necessary to screen and clean educational data so that when released to the public for analysis and archival, the students' risk are mitigated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c47b1",
   "metadata": {
    "id": "Sh7s_CBjbahT",
    "papermill": {
     "duration": 0.011126,
     "end_time": "2024-04-23T18:40:55.736487",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.725361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85099b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:40:55.760267Z",
     "iopub.status.busy": "2024-04-23T18:40:55.759988Z",
     "iopub.status.idle": "2024-04-23T18:41:32.676747Z",
     "shell.execute_reply": "2024-04-23T18:41:32.675406Z"
    },
    "id": "TP4-5t-sbcdn",
    "papermill": {
     "duration": 36.931502,
     "end_time": "2024-04-23T18:41:32.679274",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.747772",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:03.885140500Z",
     "start_time": "2024-04-24T21:25:37.722324400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rocky\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !pip install accelerate\n",
    "# !pip install seqeval\n",
    "# !pip install datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import spacy as sp\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# !pip install evaluate\n",
    "# import evaluate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "\n",
    "\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "# from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0099eb6",
   "metadata": {
    "papermill": {
     "duration": 0.012411,
     "end_time": "2024-04-23T18:41:32.705788",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.693377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390d43d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:32.733884Z",
     "iopub.status.busy": "2024-04-23T18:41:32.732522Z",
     "iopub.status.idle": "2024-04-23T18:41:32.741987Z",
     "shell.execute_reply": "2024-04-23T18:41:32.741079Z"
    },
    "papermill": {
     "duration": 0.025607,
     "end_time": "2024-04-23T18:41:32.743959",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.718352",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:03.902105400Z",
     "start_time": "2024-04-24T21:26:03.886104600Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, platform, model_name, pretrained_model_name):\n",
    "        # platform = 'Kaggle'# \n",
    "        if platform == 'kaggle':\n",
    "            pretrained_model_loc = '/kaggle/input/huggingface-bert/' + pretrained_model_name\n",
    "            data_path = \"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"\n",
    "            test_data_path = \"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"\n",
    "            model_path_out = '/kaggle/working/models/' + model_name\n",
    "            submission_path = '/kaggle/working/submission.csv'\n",
    "\n",
    "        elif platform == 'local':\n",
    "            pretrained_model_loc = pretrained_model_name\n",
    "            model_path_out = '../models/bert_models/' + model_name\n",
    "            data_path = \"../Datasets/Official/train.json\"\n",
    "            submission_path = '../models/submission/'+ model_name + '-submission.csv'\n",
    "            test_data_path = \"../Datasets/Official/test.json\"\n",
    "            \n",
    "        self.config = {\n",
    "            'MAX_LEN': 100,\n",
    "#             'TRAIN_BATCH_SIZE': 4,\n",
    "#             'VALID_BATCH_SIZE': 2,\n",
    "            'EPOCHS': 5,\n",
    "            'LEARNING_RATE':1e-5,\n",
    "#             'MAX_GRAD_NORM': 10,\n",
    "            'device': 'cuda' if cuda.is_available() else 'cpu',\n",
    "            'data_path': data_path,\n",
    "            'test_data_path': test_data_path,\n",
    "            'model_path': model_path_out,\n",
    "            'pretrained_model': BertForTokenClassification.from_pretrained(pretrained_model_loc, num_labels = 13),\n",
    "            'tokenizer': BertTokenizerFast.from_pretrained(pretrained_model_loc),\n",
    "#             'threshold': 0.9,\n",
    "            'return_entity_level_metrics': True,\n",
    "            'ignore_subwords': True, # DO NOT CHANGE\n",
    "            'subm_path': submission_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1723ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:32.771150Z",
     "iopub.status.busy": "2024-04-23T18:41:32.770891Z",
     "iopub.status.idle": "2024-04-23T18:41:38.020287Z",
     "shell.execute_reply": "2024-04-23T18:41:38.019353Z"
    },
    "papermill": {
     "duration": 5.265643,
     "end_time": "2024-04-23T18:41:38.022648",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.757005",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:05.272303300Z",
     "start_time": "2024-04-24T21:26:03.907364300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "platform = 'local'\n",
    "pretrainend_model_name = 'bert-base-cased'\n",
    "model_num = 1\n",
    "model_name = 'model-' + str(model_num) + '-' + pretrainend_model_name\n",
    "\n",
    "config = Config(platform,model_name, pretrainend_model_name).config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5995db",
   "metadata": {
    "id": "5flL5Dcfbeij",
    "papermill": {
     "duration": 0.013315,
     "end_time": "2024-04-23T18:41:38.049259",
     "exception": false,
     "start_time": "2024-04-23T18:41:38.035944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eefd757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:38.076474Z",
     "iopub.status.busy": "2024-04-23T18:41:38.076138Z",
     "iopub.status.idle": "2024-04-23T18:41:40.589188Z",
     "shell.execute_reply": "2024-04-23T18:41:40.588432Z"
    },
    "id": "g1ogxxEqbjHk",
    "papermill": {
     "duration": 2.529282,
     "end_time": "2024-04-23T18:41:40.591456",
     "exception": false,
     "start_time": "2024-04-23T18:41:38.062174",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:06.740239200Z",
     "start_time": "2024-04-24T21:26:05.277307800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_json(config['data_path'])\n",
    "df = df_train\n",
    "# df_test = pd.read_json(config['test_data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad412d",
   "metadata": {
    "id": "8jWiYTLU1yF9",
    "papermill": {
     "duration": 0.012481,
     "end_time": "2024-04-23T18:41:40.617054",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.604573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "First we scoured the data to find the usuable text with our pretrained model with Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8fc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:40.643370Z",
     "iopub.status.busy": "2024-04-23T18:41:40.643097Z",
     "iopub.status.idle": "2024-04-23T18:41:40.648306Z",
     "shell.execute_reply": "2024-04-23T18:41:40.647474Z"
    },
    "papermill": {
     "duration": 0.020603,
     "end_time": "2024-04-23T18:41:40.650241",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.629638",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:06.755634300Z",
     "start_time": "2024-04-24T21:26:06.741221400Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [\"O\",\"B-EMAIL\", \"B-ID_NUM\", \"B-NAME_STUDENT\", \"B-PHONE_NUM\",\n",
    "              \"B-STREET_ADDRESS\", \"B-URL_PERSONAL\", \"B-USERNAME\",\n",
    "              \"I-ID_NUM\", \"I-NAME_STUDENT\", \"I-PHONE_NUM\",\n",
    "              \"I-STREET_ADDRESS\",\"I-URL_PERSONAL\"]\n",
    "\n",
    "labels_to_ids = {k: v for v, k in enumerate(labels)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896f8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:40.676406Z",
     "iopub.status.busy": "2024-04-23T18:41:40.676166Z",
     "iopub.status.idle": "2024-04-23T18:41:50.767831Z",
     "shell.execute_reply": "2024-04-23T18:41:50.766832Z"
    },
    "papermill": {
     "duration": 10.107138,
     "end_time": "2024-04-23T18:41:50.769918",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.662780",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.915293700Z",
     "start_time": "2024-04-24T21:26:06.761126300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.06184809754664311"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_space = re.compile('\\xa0|\\uf0b7|\\u200b')\n",
    "df_train.loc[:,'full_text'] = df_train.loc[:,'full_text'].replace(pattern_space, ' ')\n",
    "df_train.loc[:,'tokens'] = df_train.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern_space,tok)])\n",
    "# [,.!?-]\n",
    "df_usable_train = df_train.iloc[df_train[~(df_train.tokens.apply(len) != df_train.labels.apply(len))].index]\n",
    "1-(len(df_usable_train.document))/len(df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bcd147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.797677Z",
     "iopub.status.busy": "2024-04-23T18:41:50.797391Z",
     "iopub.status.idle": "2024-04-23T18:41:50.801509Z",
     "shell.execute_reply": "2024-04-23T18:41:50.800639Z"
    },
    "papermill": {
     "duration": 0.019779,
     "end_time": "2024-04-23T18:41:50.803310",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.783531",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.929285400Z",
     "start_time": "2024-04-24T21:26:12.916293900Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test.loc[:,'full_text'] = df_test.loc[:,'full_text'].replace(pattern_space, ' ')\n",
    "# df_test.loc[:,'tokens'] = df_test.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern_space,tok)])\n",
    "# [,.!?-]\n",
    "# df_usable_test = df_test.iloc[df_test[~(df_test.tokens.apply(len) != df_test.labels.apply(len))].index]\n",
    "# 1-(len(df_usable_test.document))/len(df.document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73cdea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.830036Z",
     "iopub.status.busy": "2024-04-23T18:41:50.829777Z",
     "iopub.status.idle": "2024-04-23T18:41:50.837918Z",
     "shell.execute_reply": "2024-04-23T18:41:50.836996Z"
    },
    "papermill": {
     "duration": 0.023735,
     "end_time": "2024-04-23T18:41:50.839776",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.816041",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.978882Z",
     "start_time": "2024-04-24T21:26:12.932286900Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_smaller_inputs(dataframe, type):\n",
    "    \"\"\"Splits the entire essays into MAX_LEN size blocks and remaps tokens and labels\n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame(columns = ['tokens','labels','document','document_location'])\n",
    "    idx_df = 0\n",
    "    max_len = config['MAX_LEN']\n",
    "    \n",
    "    for _,line in dataframe.iterrows():\n",
    "        location_counter = 0\n",
    "        tokens = line.tokens\n",
    "        if type == 'train':\n",
    "            labels = line.labels\n",
    "        document = line.document\n",
    "        items = range(0,len(tokens),max_len)\n",
    "        \n",
    "        for i in items:\n",
    "            df_out.at[idx_df,'tokens'] = tokens[i:i+max_len]\n",
    "            if type == 'train':\n",
    "                df_out.at[idx_df,'labels'] = labels[i:i+max_len]\n",
    "            df_out.at[idx_df,'document'] = document\n",
    "            df_out.at[idx_df,'document_location'] = location_counter\n",
    "            location_counter += 1\n",
    "            idx_df += 1\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c982d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.866291Z",
     "iopub.status.busy": "2024-04-23T18:41:50.866038Z",
     "iopub.status.idle": "2024-04-23T18:43:29.665648Z",
     "shell.execute_reply": "2024-04-23T18:43:29.664718Z"
    },
    "papermill": {
     "duration": 98.82887,
     "end_time": "2024-04-23T18:43:29.681313",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.852443",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:26:12.949883300Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model_input_train = make_smaller_inputs(df_usable_train,'train')\n",
    "print(len(df_model_input_train.index))\n",
    "df_model_input_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c84c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.708943Z",
     "iopub.status.busy": "2024-04-23T18:43:29.708658Z",
     "iopub.status.idle": "2024-04-23T18:43:29.712296Z",
     "shell.execute_reply": "2024-04-23T18:43:29.711480Z"
    },
    "papermill": {
     "duration": 0.019737,
     "end_time": "2024-04-23T18:43:29.714362",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.694625",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_model_input_test = make_smaller_inputs(df_test,'predict')\n",
    "# print(len(df_model_input_test.index))\n",
    "# df_model_input_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1158d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.741666Z",
     "iopub.status.busy": "2024-04-23T18:43:29.741372Z",
     "iopub.status.idle": "2024-04-23T18:43:29.745772Z",
     "shell.execute_reply": "2024-04-23T18:43:29.744921Z"
    },
    "papermill": {
     "duration": 0.019975,
     "end_time": "2024-04-23T18:43:29.747556",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.727581",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def compare2dict(list1, list2, pii_threshold):\n",
    "    return len(set(list1).intersection(set(list2))) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14682bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.774649Z",
     "iopub.status.busy": "2024-04-23T18:43:29.774382Z",
     "iopub.status.idle": "2024-04-23T18:43:30.662644Z",
     "shell.execute_reply": "2024-04-23T18:43:30.661665Z"
    },
    "papermill": {
     "duration": 0.904319,
     "end_time": "2024-04-23T18:43:30.664837",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.760518",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_trainable = df_model_input_train[df_model_input_train.apply(lambda line: compare2dict(line.labels,list(labels_to_ids.keys()),0), axis = 1)]\n",
    "df_trainable_input = pd.concat([df_trainable] * 10).sample(frac=1)\n",
    "df_trainable_input.reset_index(drop = True, inplace=True)\n",
    "df_trainable_input = df_trainable_input[['tokens','labels']]\n",
    "print(len(df_trainable_input))\n",
    "df_trainable_input.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf070fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.692871Z",
     "iopub.status.busy": "2024-04-23T18:43:30.692585Z",
     "iopub.status.idle": "2024-04-23T18:43:30.696287Z",
     "shell.execute_reply": "2024-04-23T18:43:30.695456Z"
    },
    "papermill": {
     "duration": 0.019681,
     "end_time": "2024-04-23T18:43:30.698122",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.678441",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_evaluation_input = df_model_input[['tokens','labels']]\n",
    "# df_evaluation_input.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e54394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.725953Z",
     "iopub.status.busy": "2024-04-23T18:43:30.725682Z",
     "iopub.status.idle": "2024-04-23T18:43:30.729270Z",
     "shell.execute_reply": "2024-04-23T18:43:30.728448Z"
    },
    "papermill": {
     "duration": 0.019691,
     "end_time": "2024-04-23T18:43:30.731091",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.711400",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_prediction_input = df_model_input_test[['tokens','document','document_location']]\n",
    "# df_prediction_input.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0b169",
   "metadata": {
    "papermill": {
     "duration": 0.013709,
     "end_time": "2024-04-23T18:43:30.758735",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.745026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PII Inference V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88475a",
   "metadata": {
    "papermill": {
     "duration": 0.057039,
     "end_time": "2024-04-23T18:43:30.829890",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.772851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepping Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30dd20",
   "metadata": {
    "papermill": {
     "duration": 0.013727,
     "end_time": "2024-04-23T18:43:30.857702",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.843975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function for tokenizing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc4c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.887635Z",
     "iopub.status.busy": "2024-04-23T18:43:30.886779Z",
     "iopub.status.idle": "2024-04-23T18:43:30.901862Z",
     "shell.execute_reply": "2024-04-23T18:43:30.900998Z"
    },
    "papermill": {
     "duration": 0.032581,
     "end_time": "2024-04-23T18:43:30.904039",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.871458",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def tokenize(line, tokenizer, type):\n",
    "\n",
    "    tokens = line.tokens\n",
    "    \n",
    "\n",
    "    if config['ignore_subwords']:\n",
    "        length = config['MAX_LEN']\n",
    "    else:\n",
    "        length = math.ceil(config['MAX_LEN'] * 1.2)\n",
    "        \n",
    "\n",
    "    encoding = tokenizer(tokens,\n",
    "                         is_split_into_words= True,\n",
    "                         return_offsets_mapping= True,\n",
    "                         padding= 'max_length',\n",
    "                         max_length= length)\n",
    "    \n",
    "    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "    \n",
    "    if type == 'train' or type == 'eval':\n",
    "        word_labels = line.labels\n",
    "    \n",
    "        temp_list = [0 for _ in range(length - len(word_labels))]\n",
    "        labels = [labels_to_ids[label] for label in word_labels] + temp_list\n",
    "        \n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        i = 0\n",
    "    \n",
    "        if config['ignore_subwords']:\n",
    "            #         Ignore subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0 and mapping[1] != 0:\n",
    "                    # overwrite label\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        else:\n",
    "            #         Extend subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0:\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "                    \n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return {**item}\n",
    "        \n",
    "    if type == 'predict':\n",
    "        document = line.document\n",
    "        location = line.document_location\n",
    "        \n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        labels = np.zeros(len(tokens), dtype=int)\n",
    "        i = 0\n",
    "    \n",
    "        if config['ignore_subwords']:\n",
    "            #         Ignore subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0 and mapping[1] != 0:\n",
    "                    # overwrite label\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        else:\n",
    "            #         Extend subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0:\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return {**item, 'document': document, 'location': location}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f260726",
   "metadata": {
    "papermill": {
     "duration": 0.01359,
     "end_time": "2024-04-23T18:43:30.931340",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.917750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e98d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.960488Z",
     "iopub.status.busy": "2024-04-23T18:43:30.959844Z",
     "iopub.status.idle": "2024-04-23T18:43:56.696490Z",
     "shell.execute_reply": "2024-04-23T18:43:56.695464Z"
    },
    "papermill": {
     "duration": 25.753911,
     "end_time": "2024-04-23T18:43:56.698838",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.944927",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "train_dataset_temp = df_trainable_input.apply(lambda line: tokenize(line, config['tokenizer'],'train'), axis = 1).to_list()\n",
    "# train_dataset_temp\n",
    "# train_dataset = Dataset.from_list(pd.DataFrame(data=train_dataset_temp))\n",
    "\n",
    "# from_list not implemented in this notebook's version of datasets, janky version of the above\n",
    "train_dataset = Dataset.from_dict({k: [s[k] for s in train_dataset_temp] for k in  train_dataset_temp[0].keys()})\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbf2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.732903Z",
     "iopub.status.busy": "2024-04-23T18:43:56.732067Z",
     "iopub.status.idle": "2024-04-23T18:43:56.736444Z",
     "shell.execute_reply": "2024-04-23T18:43:56.735485Z"
    },
    "papermill": {
     "duration": 0.023992,
     "end_time": "2024-04-23T18:43:56.738580",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.714588",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# eval_dataset_temp = df_evaluation_input.apply(lambda line: tokenize(line, config['tokenizer'],'eval'), axis = 1)\n",
    "# # # eval_dataset = Dataset.from_list(eval_dataset_temp)\n",
    "# eval_dataset = Dataset.from_dict({k: [s[k] for s in eval_dataset_temp] for k in  eval_dataset_temp[0].keys()})\n",
    "# eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3449fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.771434Z",
     "iopub.status.busy": "2024-04-23T18:43:56.771135Z",
     "iopub.status.idle": "2024-04-23T18:43:56.775205Z",
     "shell.execute_reply": "2024-04-23T18:43:56.774250Z"
    },
    "papermill": {
     "duration": 0.022859,
     "end_time": "2024-04-23T18:43:56.777309",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.754450",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# predict_dataset_temp = df_prediction_input.apply(lambda line: tokenize(line, config['tokenizer'],'predict'), axis = 1)\n",
    "# # predict_dataset = Dataset.from_list(predict_dataset_temp)\n",
    "# predict_dataset = Dataset.from_dict({k: [s[k] for s in predict_dataset_temp] for k in  predict_dataset_temp[0].keys()})\n",
    "# predict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c6a4b",
   "metadata": {
    "papermill": {
     "duration": 0.014038,
     "end_time": "2024-04-23T18:43:56.806283",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.792245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize parts of trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059e217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.834558Z",
     "iopub.status.busy": "2024-04-23T18:43:56.834260Z",
     "iopub.status.idle": "2024-04-23T18:43:56.838360Z",
     "shell.execute_reply": "2024-04-23T18:43:56.837577Z"
    },
    "papermill": {
     "duration": 0.020128,
     "end_time": "2024-04-23T18:43:56.840139",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.820011",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model = config['pretrained_model']\n",
    "data_collator = DataCollatorForTokenClassification(config['tokenizer'])\n",
    "# metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49a177",
   "metadata": {
    "papermill": {
     "duration": 0.013233,
     "end_time": "2024-04-23T18:43:56.866772",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.853539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function for evaluating prediction. Only available online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc5a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.894522Z",
     "iopub.status.busy": "2024-04-23T18:43:56.894230Z",
     "iopub.status.idle": "2024-04-23T18:43:56.898900Z",
     "shell.execute_reply": "2024-04-23T18:43:56.898139Z"
    },
    "papermill": {
     "duration": 0.02063,
     "end_time": "2024-04-23T18:43:56.900798",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.880168",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# def compute_metrics(p):\n",
    "#     predictions, labels = p\n",
    "#     predictions = np.argmax(-1)\n",
    "\n",
    "#     # Remove ignored index (special tokens)\n",
    "#     true_predictions = [\n",
    "#         [ids_to_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [ids_to_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "\n",
    "#     results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "#     if config['return_entity_level_metrics']:\n",
    "#         # Unpack nested dictionaries\n",
    "#         final_results = {}\n",
    "#         for key, value in results.items():\n",
    "#             if isinstance(value, dict):\n",
    "#                 for n, v in value.items():\n",
    "#                     final_results[f\"{key}_{n}\"] = v\n",
    "#             else:\n",
    "#                 final_results[key] = value\n",
    "#         return final_results\n",
    "#     else:\n",
    "#         return {\n",
    "#             \"precision\": results[\"overall_precision\"],\n",
    "#             \"recall\": results[\"overall_recall\"],\n",
    "#             \"f1\": results[\"overall_f1\"],\n",
    "#             \"accuracy\": results[\"overall_accuracy\"],\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd764d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.929958Z",
     "iopub.status.busy": "2024-04-23T18:43:56.929705Z",
     "iopub.status.idle": "2024-04-23T18:43:56.936814Z",
     "shell.execute_reply": "2024-04-23T18:43:56.936057Z"
    },
    "papermill": {
     "duration": 0.024477,
     "end_time": "2024-04-23T18:43:56.938666",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.914189",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [ids_to_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [ids_to_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "    \n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a699ae",
   "metadata": {
    "papermill": {
     "duration": 0.013093,
     "end_time": "2024-04-23T18:43:56.965190",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.952097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f633696",
   "metadata": {
    "papermill": {
     "duration": 0.013077,
     "end_time": "2024-04-23T18:43:56.991631",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.978554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1ae46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:57.019191Z",
     "iopub.status.busy": "2024-04-23T18:43:57.018953Z",
     "iopub.status.idle": "2024-04-23T18:43:57.362360Z",
     "shell.execute_reply": "2024-04-23T18:43:57.361331Z"
    },
    "papermill": {
     "duration": 0.359818,
     "end_time": "2024-04-23T18:43:57.364774",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.004956",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= config['model_path'],\n",
    "#     overwrite_output_dir = True,\n",
    "    do_train = True,\n",
    "#     do_predict = True,\n",
    "#     do_eval = False,\n",
    "#     per_device_eval_batch_size=1,\n",
    "    auto_find_batch_size=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs = config['EPOCHS'],\n",
    "    learning_rate = config['LEARNING_RATE'],\n",
    "    save_strategy = 'no',\n",
    "    disable_tqdm= False,\n",
    "    no_cuda = False,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = train_dataset,\n",
    "#     eval_dataset = eval_dataset,\n",
    "    # predict_dataset = predict_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02bf7e",
   "metadata": {
    "papermill": {
     "duration": 0.013718,
     "end_time": "2024-04-23T18:43:57.392539",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.378821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd24ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:57.421891Z",
     "iopub.status.busy": "2024-04-23T18:43:57.421143Z",
     "iopub.status.idle": "2024-04-23T18:58:33.958862Z",
     "shell.execute_reply": "2024-04-23T18:58:33.957801Z"
    },
    "papermill": {
     "duration": 876.554595,
     "end_time": "2024-04-23T18:58:33.961040",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.406445",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    train_result = trainer.train()\n",
    "    metrics = train_result.metrics\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    metrics[\"train_samples\"] = len(train_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "#     trainer.save_metrics(\"train\", metrics)\n",
    "    # trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c77b1",
   "metadata": {
    "papermill": {
     "duration": 0.013858,
     "end_time": "2024-04-23T18:58:33.989548",
     "exception": false,
     "start_time": "2024-04-23T18:58:33.975690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reassign model from kaggle output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b9580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.020675Z",
     "iopub.status.busy": "2024-04-23T18:58:34.020321Z",
     "iopub.status.idle": "2024-04-23T18:58:34.024296Z",
     "shell.execute_reply": "2024-04-23T18:58:34.023363Z"
    },
    "papermill": {
     "duration": 0.022448,
     "end_time": "2024-04-23T18:58:34.026184",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.003736",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# trainer.model = BertForTokenClassification.from_pretrained(config['model_path'])\n",
    "# trainer.model.to(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76329e2d",
   "metadata": {
    "papermill": {
     "duration": 0.013746,
     "end_time": "2024-04-23T18:58:34.054241",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.040495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a086658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.083995Z",
     "iopub.status.busy": "2024-04-23T18:58:34.083347Z",
     "iopub.status.idle": "2024-04-23T18:58:34.087647Z",
     "shell.execute_reply": "2024-04-23T18:58:34.086735Z"
    },
    "papermill": {
     "duration": 0.021086,
     "end_time": "2024-04-23T18:58:34.089579",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.068493",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# if training_args.do_eval:\n",
    "# #     logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "#     metrics = trainer.evaluate()\n",
    "\n",
    "#  #   max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "#     metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "\n",
    "#     trainer.log_metrics(\"eval\", metrics)\n",
    "#     trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fd710",
   "metadata": {
    "papermill": {
     "duration": 0.013644,
     "end_time": "2024-04-23T18:58:34.116985",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.103341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6e15b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.146038Z",
     "iopub.status.busy": "2024-04-23T18:58:34.145611Z",
     "iopub.status.idle": "2024-04-23T18:58:34.150232Z",
     "shell.execute_reply": "2024-04-23T18:58:34.149425Z"
    },
    "papermill": {
     "duration": 0.021215,
     "end_time": "2024-04-23T18:58:34.152098",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.130883",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# if training_args.do_predict:\n",
    "#     # logger.info(\"*** Predict ***\")\n",
    "\n",
    "#     predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "#     predictions = predictions.argmax(-1)\n",
    "\n",
    "#     # Remove ignored index (special tokens)\n",
    "#     true_predictions = [\n",
    "#         [ids_to_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "\n",
    "# #     trainer.log_metrics(\"predict\", metrics)\n",
    "# #     trainer.save_metrics(\"predict\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc920e89",
   "metadata": {
    "papermill": {
     "duration": 0.013523,
     "end_time": "2024-04-23T18:58:34.179478",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.165955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15503e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.208259Z",
     "iopub.status.busy": "2024-04-23T18:58:34.208000Z",
     "iopub.status.idle": "2024-04-23T18:58:34.211988Z",
     "shell.execute_reply": "2024-04-23T18:58:34.211113Z"
    },
    "papermill": {
     "duration": 0.020713,
     "end_time": "2024-04-23T18:58:34.214000",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.193287",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for preds, location, doc in zip(\n",
    "#     true_predictions, \n",
    "#     predict_dataset[\"location\"], \n",
    "#     predict_dataset[\"document\"]\n",
    "# ):\n",
    "#     results.extend([(doc, location * config['MAX_LEN'] + idx, label) for idx, label in enumerate(preds) if label != 'O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb5b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.243057Z",
     "iopub.status.busy": "2024-04-23T18:58:34.242376Z",
     "iopub.status.idle": "2024-04-23T18:58:34.246112Z",
     "shell.execute_reply": "2024-04-23T18:58:34.245352Z"
    },
    "papermill": {
     "duration": 0.020049,
     "end_time": "2024-04-23T18:58:34.248010",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.227961",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame(results, columns = ['document','token','label'])\n",
    "# df_submission['row_id'] = df_submission.index\n",
    "# df_submission_final = df_submission[['row_id','document','token','label']]\n",
    "# df_submission_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3c835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.276909Z",
     "iopub.status.busy": "2024-04-23T18:58:34.276661Z",
     "iopub.status.idle": "2024-04-23T18:58:34.280265Z",
     "shell.execute_reply": "2024-04-23T18:58:34.279480Z"
    },
    "papermill": {
     "duration": 0.02022,
     "end_time": "2024-04-23T18:58:34.282103",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.261883",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_submission_final.to_csv(config['subm_path'],index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765ac10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.310865Z",
     "iopub.status.busy": "2024-04-23T18:58:34.310608Z",
     "iopub.status.idle": "2024-04-23T18:58:34.314275Z",
     "shell.execute_reply": "2024-04-23T18:58:34.313454Z"
    },
    "papermill": {
     "duration": 0.019999,
     "end_time": "2024-04-23T18:58:34.316075",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.296076",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# df_submission_final.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37316ba",
   "metadata": {
    "papermill": {
     "duration": 0.013521,
     "end_time": "2024-04-23T18:58:34.343399",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.329878",
     "status": "completed"
    },
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 934701,
     "sourceId": 8169098,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1064.784835,
   "end_time": "2024-04-23T18:58:37.478230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-23T18:40:52.693395",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
