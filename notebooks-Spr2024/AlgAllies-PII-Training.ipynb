{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a288ec",
   "metadata": {
    "id": "chcr1ibHHbS_",
    "papermill": {
     "duration": 0.011865,
     "end_time": "2024-04-23T18:40:55.713949",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.702084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identifying PII in Student Essays\n",
    "## Authored by: Pratik Chaudhari, Cody Ledford, Manu Achar\n",
    "## Project Summary\n",
    "The Kaggle Competition we are participating in is the [PII Data Detection hosted by The Learning Agency Lab](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview). The goal of this competition is to develop a model that detects sensitive personally identifiable information (PII) in student writing. This is necessary to screen and clean educational data so that when released to the public for analysis and archival, the students' risk are mitigated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c47b1",
   "metadata": {
    "id": "Sh7s_CBjbahT",
    "papermill": {
     "duration": 0.011126,
     "end_time": "2024-04-23T18:40:55.736487",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.725361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85099b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:03.885140500Z",
     "start_time": "2024-04-24T21:25:37.722324400Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:40:55.760267Z",
     "iopub.status.busy": "2024-04-23T18:40:55.759988Z",
     "iopub.status.idle": "2024-04-23T18:41:32.676747Z",
     "shell.execute_reply": "2024-04-23T18:41:32.675406Z"
    },
    "id": "TP4-5t-sbcdn",
    "papermill": {
     "duration": 36.931502,
     "end_time": "2024-04-23T18:41:32.679274",
     "exception": false,
     "start_time": "2024-04-23T18:40:55.747772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !pip install accelerate\n",
    "# !pip install seqeval\n",
    "# !pip install datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import spacy as sp\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# !pip install evaluate\n",
    "# import evaluate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "\n",
    "\n",
    "from seqeval.metrics import recall_score, precision_score\n",
    "# from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0099eb6",
   "metadata": {
    "papermill": {
     "duration": 0.012411,
     "end_time": "2024-04-23T18:41:32.705788",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.693377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390d43d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:03.902105400Z",
     "start_time": "2024-04-24T21:26:03.886104600Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:32.733884Z",
     "iopub.status.busy": "2024-04-23T18:41:32.732522Z",
     "iopub.status.idle": "2024-04-23T18:41:32.741987Z",
     "shell.execute_reply": "2024-04-23T18:41:32.741079Z"
    },
    "papermill": {
     "duration": 0.025607,
     "end_time": "2024-04-23T18:41:32.743959",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.718352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, platform, model_name, pretrained_model_name):\n",
    "        # platform = 'Kaggle'# \n",
    "        if platform == 'kaggle':\n",
    "            pretrained_model_loc = '/kaggle/input/huggingface-bert/' + pretrained_model_name\n",
    "            data_path = \"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"\n",
    "            test_data_path = \"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"\n",
    "            model_path_out = '/kaggle/working/models/' + model_name\n",
    "            submission_path = '/kaggle/working/submission.csv'\n",
    "\n",
    "        elif platform == 'local':\n",
    "            pretrained_model_loc = pretrained_model_name\n",
    "            model_path_out = '../models/bert_models/' + model_name\n",
    "            data_path = \"../Datasets/Official/train.json\"\n",
    "            submission_path = '../models/submission/'+ model_name + '-submission.csv'\n",
    "            test_data_path = \"../Datasets/Official/test.json\"\n",
    "            \n",
    "        self.config = {\n",
    "            'MAX_LEN': 100,\n",
    "#             'TRAIN_BATCH_SIZE': 4,\n",
    "#             'VALID_BATCH_SIZE': 2,\n",
    "            'EPOCHS': 5,\n",
    "            'LEARNING_RATE':1e-5,\n",
    "#             'MAX_GRAD_NORM': 10,\n",
    "            'device': 'cuda' if cuda.is_available() else 'cpu',\n",
    "            'data_path': data_path,\n",
    "            'test_data_path': test_data_path,\n",
    "            'model_path': model_path_out,\n",
    "            'pretrained_model': BertForTokenClassification.from_pretrained(pretrained_model_loc, num_labels = 13),\n",
    "            'tokenizer': BertTokenizerFast.from_pretrained(pretrained_model_loc),\n",
    "#             'threshold': 0.9,\n",
    "            'return_entity_level_metrics': True,\n",
    "            'ignore_subwords': True, # DO NOT CHANGE\n",
    "            'subm_path': submission_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1723ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:05.272303300Z",
     "start_time": "2024-04-24T21:26:03.907364300Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:32.771150Z",
     "iopub.status.busy": "2024-04-23T18:41:32.770891Z",
     "iopub.status.idle": "2024-04-23T18:41:38.020287Z",
     "shell.execute_reply": "2024-04-23T18:41:38.019353Z"
    },
    "papermill": {
     "duration": 5.265643,
     "end_time": "2024-04-23T18:41:38.022648",
     "exception": false,
     "start_time": "2024-04-23T18:41:32.757005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "platform = 'local'\n",
    "pretrainend_model_name = 'bert-base-cased'\n",
    "model_num = 1\n",
    "model_name = 'model-' + str(model_num) + '-' + pretrainend_model_name\n",
    "\n",
    "config = Config(platform,model_name, pretrainend_model_name).config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5995db",
   "metadata": {
    "id": "5flL5Dcfbeij",
    "papermill": {
     "duration": 0.013315,
     "end_time": "2024-04-23T18:41:38.049259",
     "exception": false,
     "start_time": "2024-04-23T18:41:38.035944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1eefd757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:06.740239200Z",
     "start_time": "2024-04-24T21:26:05.277307800Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:38.076474Z",
     "iopub.status.busy": "2024-04-23T18:41:38.076138Z",
     "iopub.status.idle": "2024-04-23T18:41:40.589188Z",
     "shell.execute_reply": "2024-04-23T18:41:40.588432Z"
    },
    "id": "g1ogxxEqbjHk",
    "papermill": {
     "duration": 2.529282,
     "end_time": "2024-04-23T18:41:40.591456",
     "exception": false,
     "start_time": "2024-04-23T18:41:38.062174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>22678</td>\n",
       "      <td>EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...</td>\n",
       "      <td>[EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...</td>\n",
       "      <td>[True, True, True, False, False, True, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>22679</td>\n",
       "      <td>Why Mind Mapping?\\n\\nMind maps are graphical r...</td>\n",
       "      <td>[Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...</td>\n",
       "      <td>[True, True, False, False, False, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>22681</td>\n",
       "      <td>Challenge\\n\\nSo, a few months back, I had chos...</td>\n",
       "      <td>[Challenge, \\n\\n, So, ,, a, few, months, back,...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>22684</td>\n",
       "      <td>Brainstorming\\n\\nChallenge &amp; Selection\\n\\nBrai...</td>\n",
       "      <td>[Brainstorming, \\n\\n, Challenge, &amp;, Selection,...</td>\n",
       "      <td>[False, False, True, True, False, False, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>22687</td>\n",
       "      <td>Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...</td>\n",
       "      <td>[Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                          full_text  \\\n",
       "0            7  Design Thinking for innovation reflexion-Avril...   \n",
       "1           10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2           16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3           20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4           56  Assignment:  Visualization Reflection  Submitt...   \n",
       "...        ...                                                ...   \n",
       "6802     22678  EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...   \n",
       "6803     22679  Why Mind Mapping?\\n\\nMind maps are graphical r...   \n",
       "6804     22681  Challenge\\n\\nSo, a few months back, I had chos...   \n",
       "6805     22684  Brainstorming\\n\\nChallenge & Selection\\n\\nBrai...   \n",
       "6806     22687  Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Design, Thinking, for, innovation, reflexion,...   \n",
       "1     [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2     [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3     [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4     [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "...                                                 ...   \n",
       "6802  [EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...   \n",
       "6803  [Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...   \n",
       "6804  [Challenge, \\n\\n, So, ,, a, few, months, back,...   \n",
       "6805  [Brainstorming, \\n\\n, Challenge, &, Selection,...   \n",
       "6806  [Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "0     [True, True, True, True, False, False, True, F...   \n",
       "1     [True, False, False, True, True, False, False,...   \n",
       "2     [True, False, False, True, True, False, False,...   \n",
       "3     [True, True, True, False, False, True, False, ...   \n",
       "4     [False, False, False, False, False, False, Fal...   \n",
       "...                                                 ...   \n",
       "6802  [True, True, True, False, False, True, True, F...   \n",
       "6803  [True, True, False, False, False, True, True, ...   \n",
       "6804  [False, False, False, True, True, True, True, ...   \n",
       "6805  [False, False, True, True, False, False, True,...   \n",
       "6806  [True, False, False, False, False, True, True,...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1     [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2     [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3     [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n",
       "...                                                 ...  \n",
       "6802  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6803  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6804  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6805  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6806  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[6807 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json(config['data_path'])\n",
    "df = df_train\n",
    "df\n",
    "# df_test = pd.read_json(config['test_data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad412d",
   "metadata": {
    "id": "8jWiYTLU1yF9",
    "papermill": {
     "duration": 0.012481,
     "end_time": "2024-04-23T18:41:40.617054",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.604573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "First we scoured the data to find the usuable text with our pretrained model with Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8fc06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:06.755634300Z",
     "start_time": "2024-04-24T21:26:06.741221400Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:40.643370Z",
     "iopub.status.busy": "2024-04-23T18:41:40.643097Z",
     "iopub.status.idle": "2024-04-23T18:41:40.648306Z",
     "shell.execute_reply": "2024-04-23T18:41:40.647474Z"
    },
    "papermill": {
     "duration": 0.020603,
     "end_time": "2024-04-23T18:41:40.650241",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.629638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\"O\",\"B-EMAIL\", \"B-ID_NUM\", \"B-NAME_STUDENT\", \"B-PHONE_NUM\",\n",
    "              \"B-STREET_ADDRESS\", \"B-URL_PERSONAL\", \"B-USERNAME\",\n",
    "              \"I-ID_NUM\", \"I-NAME_STUDENT\", \"I-PHONE_NUM\",\n",
    "              \"I-STREET_ADDRESS\",\"I-URL_PERSONAL\"]\n",
    "\n",
    "labels_to_ids = {k: v for v, k in enumerate(labels)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896f8104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.915293700Z",
     "start_time": "2024-04-24T21:26:06.761126300Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:40.676406Z",
     "iopub.status.busy": "2024-04-23T18:41:40.676166Z",
     "iopub.status.idle": "2024-04-23T18:41:50.767831Z",
     "shell.execute_reply": "2024-04-23T18:41:50.766832Z"
    },
    "papermill": {
     "duration": 10.107138,
     "end_time": "2024-04-23T18:41:50.769918",
     "exception": false,
     "start_time": "2024-04-23T18:41:40.662780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06184809754664311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_space = re.compile('\\xa0|\\uf0b7|\\u200b')\n",
    "df_train.loc[:,'full_text'] = df_train.loc[:,'full_text'].replace(pattern_space, ' ')\n",
    "df_train.loc[:,'tokens'] = df_train.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern_space,tok)])\n",
    "# [,.!?-]\n",
    "df_usable_train = df_train.iloc[df_train[~(df_train.tokens.apply(len) != df_train.labels.apply(len))].index]\n",
    "1-(len(df_usable_train.document))/len(df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bcd147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.929285400Z",
     "start_time": "2024-04-24T21:26:12.916293900Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.797677Z",
     "iopub.status.busy": "2024-04-23T18:41:50.797391Z",
     "iopub.status.idle": "2024-04-23T18:41:50.801509Z",
     "shell.execute_reply": "2024-04-23T18:41:50.800639Z"
    },
    "papermill": {
     "duration": 0.019779,
     "end_time": "2024-04-23T18:41:50.803310",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.783531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test.loc[:,'full_text'] = df_test.loc[:,'full_text'].replace(pattern_space, ' ')\n",
    "# df_test.loc[:,'tokens'] = df_test.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern_space,tok)])\n",
    "# [,.!?-]\n",
    "# df_usable_test = df_test.iloc[df_test[~(df_test.tokens.apply(len) != df_test.labels.apply(len))].index]\n",
    "# 1-(len(df_usable_test.document))/len(df.document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73cdea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T21:26:12.978882Z",
     "start_time": "2024-04-24T21:26:12.932286900Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.830036Z",
     "iopub.status.busy": "2024-04-23T18:41:50.829777Z",
     "iopub.status.idle": "2024-04-23T18:41:50.837918Z",
     "shell.execute_reply": "2024-04-23T18:41:50.836996Z"
    },
    "papermill": {
     "duration": 0.023735,
     "end_time": "2024-04-23T18:41:50.839776",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.816041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_smaller_inputs(dataframe, type):\n",
    "    \"\"\"Splits the entire essays into MAX_LEN size blocks and remaps tokens and labels\n",
    "    \"\"\"\n",
    "    df_out = pd.DataFrame(columns = ['tokens','labels','document','document_location'])\n",
    "    idx_df = 0\n",
    "    max_len = config['MAX_LEN']\n",
    "    \n",
    "    for _,line in dataframe.iterrows():\n",
    "        location_counter = 0\n",
    "        tokens = line.tokens\n",
    "        if type == 'train':\n",
    "            labels = line.labels\n",
    "        document = line.document\n",
    "        items = range(0,len(tokens),max_len)\n",
    "        \n",
    "        for i in items:\n",
    "            df_out.at[idx_df,'tokens'] = tokens[i:i+max_len]\n",
    "            if type == 'train':\n",
    "                df_out.at[idx_df,'labels'] = labels[i:i+max_len]\n",
    "            df_out.at[idx_df,'document'] = document\n",
    "            df_out.at[idx_df,'document_location'] = location_counter\n",
    "            location_counter += 1\n",
    "            idx_df += 1\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5c982d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-24T21:26:12.949883300Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-23T18:41:50.866291Z",
     "iopub.status.busy": "2024-04-23T18:41:50.866038Z",
     "iopub.status.idle": "2024-04-23T18:43:29.665648Z",
     "shell.execute_reply": "2024-04-23T18:43:29.664718Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 98.82887,
     "end_time": "2024-04-23T18:43:29.681313",
     "exception": false,
     "start_time": "2024-04-23T18:41:50.852443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>document</th>\n",
       "      <th>document_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['s,  , potential, to, be, released, ., Cf, An...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  ['s,  , potential, to, be, released, ., Cf, An...   \n",
       "\n",
       "                                              labels document  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...        7   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...        7   \n",
       "\n",
       "  document_location  \n",
       "0                 0  \n",
       "1                 1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_input_train = make_smaller_inputs(df_usable_train,'train')\n",
    "print(len(df_model_input_train.index))\n",
    "df_model_input_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645c84c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.708943Z",
     "iopub.status.busy": "2024-04-23T18:43:29.708658Z",
     "iopub.status.idle": "2024-04-23T18:43:29.712296Z",
     "shell.execute_reply": "2024-04-23T18:43:29.711480Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.019737,
     "end_time": "2024-04-23T18:43:29.714362",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.694625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_model_input_test = make_smaller_inputs(df_test,'predict')\n",
    "# print(len(df_model_input_test.index))\n",
    "# df_model_input_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a1158d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.741666Z",
     "iopub.status.busy": "2024-04-23T18:43:29.741372Z",
     "iopub.status.idle": "2024-04-23T18:43:29.745772Z",
     "shell.execute_reply": "2024-04-23T18:43:29.744921Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.019975,
     "end_time": "2024-04-23T18:43:29.747556",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.727581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare2dict(list1, list2, pii_threshold):\n",
    "    return len(set(list1).intersection(set(list2))) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14682bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:29.774649Z",
     "iopub.status.busy": "2024-04-23T18:43:29.774382Z",
     "iopub.status.idle": "2024-04-23T18:43:30.662644Z",
     "shell.execute_reply": "2024-04-23T18:43:30.661665Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.904319,
     "end_time": "2024-04-23T18:43:30.664837",
     "exception": false,
     "start_time": "2024-04-23T18:43:29.760518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[need, them, to,  , amplify, their, social, im...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Reflection, |, Mind, Mapping, \\n\\n, Isabel, P...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [need, them, to,  , amplify, their, social, im...   \n",
       "1  [Reflection, |, Mind, Mapping, \\n\\n, Isabel, P...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainable = df_model_input_train[df_model_input_train.apply(lambda line: compare2dict(line.labels,list(labels_to_ids.keys()),0), axis = 1)]\n",
    "df_trainable_input = pd.concat([df_trainable] * 10).sample(frac=1)\n",
    "df_trainable_input.reset_index(drop = True, inplace=True)\n",
    "df_trainable_input = df_trainable_input[['tokens','labels']]\n",
    "print(len(df_trainable_input))\n",
    "df_trainable_input.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf070fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.692871Z",
     "iopub.status.busy": "2024-04-23T18:43:30.692585Z",
     "iopub.status.idle": "2024-04-23T18:43:30.696287Z",
     "shell.execute_reply": "2024-04-23T18:43:30.695456Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.019681,
     "end_time": "2024-04-23T18:43:30.698122",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.678441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_evaluation_input = df_model_input[['tokens','labels']]\n",
    "# df_evaluation_input.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0b169",
   "metadata": {
    "papermill": {
     "duration": 0.013709,
     "end_time": "2024-04-23T18:43:30.758735",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.745026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PII Inference V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88475a",
   "metadata": {
    "papermill": {
     "duration": 0.057039,
     "end_time": "2024-04-23T18:43:30.829890",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.772851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepping Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30dd20",
   "metadata": {
    "papermill": {
     "duration": 0.013727,
     "end_time": "2024-04-23T18:43:30.857702",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.843975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function for tokenizing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4cc4c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.887635Z",
     "iopub.status.busy": "2024-04-23T18:43:30.886779Z",
     "iopub.status.idle": "2024-04-23T18:43:30.901862Z",
     "shell.execute_reply": "2024-04-23T18:43:30.900998Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.032581,
     "end_time": "2024-04-23T18:43:30.904039",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.871458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(line, tokenizer, type):\n",
    "\n",
    "    tokens = line.tokens\n",
    "    \n",
    "\n",
    "    if config['ignore_subwords']:\n",
    "        length = config['MAX_LEN']\n",
    "    else:\n",
    "        length = math.ceil(config['MAX_LEN'] * 1.2)\n",
    "        \n",
    "\n",
    "    encoding = tokenizer(tokens,\n",
    "                         is_split_into_words= True,\n",
    "                         return_offsets_mapping= True,\n",
    "                         padding= 'max_length',\n",
    "                         max_length= length)\n",
    "    \n",
    "    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "    \n",
    "    if type == 'train' or type == 'eval':\n",
    "        word_labels = line.labels\n",
    "    \n",
    "        temp_list = [0 for _ in range(length - len(word_labels))]\n",
    "        labels = [labels_to_ids[label] for label in word_labels] + temp_list\n",
    "        \n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        i = 0\n",
    "    \n",
    "        if config['ignore_subwords']:\n",
    "            #         Ignore subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0 and mapping[1] != 0:\n",
    "                    # overwrite label\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        else:\n",
    "            #         Extend subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0:\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "                    \n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return {**item}\n",
    "        \n",
    "    if type == 'predict':\n",
    "        document = line.document\n",
    "        location = line.document_location\n",
    "        \n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        labels = np.zeros(len(tokens), dtype=int)\n",
    "        i = 0\n",
    "    \n",
    "        if config['ignore_subwords']:\n",
    "            #         Ignore subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0 and mapping[1] != 0:\n",
    "                    # overwrite label\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        else:\n",
    "            #         Extend subword labels\n",
    "            for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "                if mapping[0] == 0:\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return {**item, 'document': document, 'location': location}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f260726",
   "metadata": {
    "papermill": {
     "duration": 0.01359,
     "end_time": "2024-04-23T18:43:30.931340",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.917750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e98d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:30.960488Z",
     "iopub.status.busy": "2024-04-23T18:43:30.959844Z",
     "iopub.status.idle": "2024-04-23T18:43:56.696490Z",
     "shell.execute_reply": "2024-04-23T18:43:56.695464Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 25.753911,
     "end_time": "2024-04-23T18:43:56.698838",
     "exception": false,
     "start_time": "2024-04-23T18:43:30.944927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'labels'],\n",
       "    num_rows: 11560\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_temp = df_trainable_input.apply(lambda line: tokenize(line, config['tokenizer'],'train'), axis = 1).to_list()\n",
    "# train_dataset_temp\n",
    "# train_dataset = Dataset.from_list(pd.DataFrame(data=train_dataset_temp))\n",
    "\n",
    "# from_list not implemented in this notebook's version of datasets, the process below creates what from_list would have created.\n",
    "train_dataset = Dataset.from_dict({k: [s[k] for s in train_dataset_temp] for k in  train_dataset_temp[0].keys()})\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbdbf2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.732903Z",
     "iopub.status.busy": "2024-04-23T18:43:56.732067Z",
     "iopub.status.idle": "2024-04-23T18:43:56.736444Z",
     "shell.execute_reply": "2024-04-23T18:43:56.735485Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.023992,
     "end_time": "2024-04-23T18:43:56.738580",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.714588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_dataset_temp = df_evaluation_input.apply(lambda line: tokenize(line, config['tokenizer'],'eval'), axis = 1)\n",
    "# # # eval_dataset = Dataset.from_list(eval_dataset_temp)\n",
    "# eval_dataset = Dataset.from_dict({k: [s[k] for s in eval_dataset_temp] for k in  eval_dataset_temp[0].keys()})\n",
    "# eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c6a4b",
   "metadata": {
    "papermill": {
     "duration": 0.014038,
     "end_time": "2024-04-23T18:43:56.806283",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.792245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize parts of trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d059e217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.834558Z",
     "iopub.status.busy": "2024-04-23T18:43:56.834260Z",
     "iopub.status.idle": "2024-04-23T18:43:56.838360Z",
     "shell.execute_reply": "2024-04-23T18:43:56.837577Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.020128,
     "end_time": "2024-04-23T18:43:56.840139",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.820011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = config['pretrained_model']\n",
    "data_collator = DataCollatorForTokenClassification(config['tokenizer'])\n",
    "# metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49a177",
   "metadata": {
    "papermill": {
     "duration": 0.013233,
     "end_time": "2024-04-23T18:43:56.866772",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.853539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function for evaluating prediction. Only available online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd764d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:56.929958Z",
     "iopub.status.busy": "2024-04-23T18:43:56.929705Z",
     "iopub.status.idle": "2024-04-23T18:43:56.936814Z",
     "shell.execute_reply": "2024-04-23T18:43:56.936057Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.024477,
     "end_time": "2024-04-23T18:43:56.938666",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.914189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(-1)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [ids_to_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [ids_to_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "    \n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a699ae",
   "metadata": {
    "papermill": {
     "duration": 0.013093,
     "end_time": "2024-04-23T18:43:56.965190",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.952097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f633696",
   "metadata": {
    "papermill": {
     "duration": 0.013077,
     "end_time": "2024-04-23T18:43:56.991631",
     "exception": false,
     "start_time": "2024-04-23T18:43:56.978554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb1ae46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:57.019191Z",
     "iopub.status.busy": "2024-04-23T18:43:57.018953Z",
     "iopub.status.idle": "2024-04-23T18:43:57.362360Z",
     "shell.execute_reply": "2024-04-23T18:43:57.361331Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.359818,
     "end_time": "2024-04-23T18:43:57.364774",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.004956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= config['model_path'],\n",
    "    # overwrite_output_dir = True,\n",
    "    do_train = True,\n",
    "    # do_eval = False,\n",
    "    # per_device_eval_batch_size=1,\n",
    "    auto_find_batch_size=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs = config['EPOCHS'],\n",
    "    learning_rate = config['LEARNING_RATE'],\n",
    "    save_strategy = 'no',\n",
    "    disable_tqdm= False,\n",
    "    no_cuda = False,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    # eval_dataset = eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02bf7e",
   "metadata": {
    "papermill": {
     "duration": 0.013718,
     "end_time": "2024-04-23T18:43:57.392539",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.378821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcd24ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:43:57.421891Z",
     "iopub.status.busy": "2024-04-23T18:43:57.421143Z",
     "iopub.status.idle": "2024-04-23T18:58:33.958862Z",
     "shell.execute_reply": "2024-04-23T18:58:33.957801Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 876.554595,
     "end_time": "2024-04-23T18:58:33.961040",
     "exception": false,
     "start_time": "2024-04-23T18:43:57.406445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3db43d748e24ec290f359b9dcb68d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1216, 'grad_norm': 0.6488198637962341, 'learning_rate': 9.307958477508652e-06, 'epoch': 0.35}\n",
      "{'loss': 0.0312, 'grad_norm': 0.07275829464197159, 'learning_rate': 8.615916955017302e-06, 'epoch': 0.69}\n",
      "{'loss': 0.0194, 'grad_norm': 1.0691379308700562, 'learning_rate': 7.923875432525952e-06, 'epoch': 1.04}\n",
      "{'loss': 0.012, 'grad_norm': 1.118030309677124, 'learning_rate': 7.2318339100346025e-06, 'epoch': 1.38}\n",
      "{'loss': 0.0071, 'grad_norm': 0.576580822467804, 'learning_rate': 6.539792387543253e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0046, 'grad_norm': 0.3281711935997009, 'learning_rate': 5.847750865051903e-06, 'epoch': 2.08}\n",
      "{'loss': 0.0035, 'grad_norm': 0.0562983863055706, 'learning_rate': 5.155709342560554e-06, 'epoch': 2.42}\n",
      "{'loss': 0.002, 'grad_norm': 2.3867671489715576, 'learning_rate': 4.463667820069205e-06, 'epoch': 2.77}\n",
      "{'loss': 0.002, 'grad_norm': 0.7267292141914368, 'learning_rate': 3.7716262975778552e-06, 'epoch': 3.11}\n",
      "{'loss': 0.0014, 'grad_norm': 0.1894765943288803, 'learning_rate': 3.0795847750865054e-06, 'epoch': 3.46}\n",
      "{'loss': 0.0011, 'grad_norm': 0.06794597208499908, 'learning_rate': 2.387543252595156e-06, 'epoch': 3.81}\n",
      "{'loss': 0.0009, 'grad_norm': 0.06823647022247314, 'learning_rate': 1.6955017301038063e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0008, 'grad_norm': 0.42728620767593384, 'learning_rate': 1.0034602076124569e-06, 'epoch': 4.5}\n",
      "{'loss': 0.0007, 'grad_norm': 0.0790964886546135, 'learning_rate': 3.114186851211073e-07, 'epoch': 4.84}\n",
      "{'train_runtime': 967.5827, 'train_samples_per_second': 59.736, 'train_steps_per_second': 7.467, 'train_loss': 0.014433691272686098, 'epoch': 5.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     0.0144\n",
      "  train_runtime            = 0:16:07.58\n",
      "  train_samples            =      11560\n",
      "  train_samples_per_second =     59.736\n",
      "  train_steps_per_second   =      7.467\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    train_result = trainer.train()\n",
    "    metrics = train_result.metrics\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    metrics[\"train_samples\"] = len(train_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    # trainer.save_metrics(\"train\", metrics)\n",
    "    # trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76329e2d",
   "metadata": {
    "papermill": {
     "duration": 0.013746,
     "end_time": "2024-04-23T18:58:34.054241",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.040495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a086658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T18:58:34.083995Z",
     "iopub.status.busy": "2024-04-23T18:58:34.083347Z",
     "iopub.status.idle": "2024-04-23T18:58:34.087647Z",
     "shell.execute_reply": "2024-04-23T18:58:34.086735Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 0.021086,
     "end_time": "2024-04-23T18:58:34.089579",
     "exception": false,
     "start_time": "2024-04-23T18:58:34.068493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# if training_args.do_eval:\n",
    "# #     logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "#     metrics = trainer.evaluate()\n",
    "\n",
    "#  #   max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "#     metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "\n",
    "#     trainer.log_metrics(\"eval\", metrics)\n",
    "#     trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 934701,
     "sourceId": 8169098,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1064.784835,
   "end_time": "2024-04-23T18:58:37.478230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-23T18:40:52.693395",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
