{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chcr1ibHHbS_",
   "metadata": {
    "id": "chcr1ibHHbS_"
   },
   "source": [
    "# Identifying PII in Student Essays\n",
    "## Project Summary\n",
    "The Kaggle Competition we are participating in is the [PII Data Detection hosted by The Learning Agency Lab](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview). The goal of this competition is to develop a model that detects sensitive personally identifiable information (PII) in student writing. This is necessary to screen and clean educational data so that when released to the public for analysis and archival, the students' risk are mitigated.\n",
    "\n",
    "## Cloning Repo\n",
    "Because one of the files is larger than 100MiB, the file could not be uploaded directly to the github repo. The solution found was using git large file system to hold the file and upload the git lfs pointer file in the place of the json.\n",
    "\n",
    "Git Bash Code:\n",
    "```\n",
    "# install git lfs\n",
    "git lfs install\n",
    "\n",
    "# start file tracking for git lfs in the repo\n",
    "git lfs track \"*.json\"\n",
    "\n",
    "# stage/commit/push training json\n",
    "git add train.json\n",
    "git commit -m \"add train.json\"\n",
    "git push\n",
    "```\n",
    "After cloning the repo locally, it clones the git lfs pointer file not the data file.\n",
    "\n",
    "Git Bash Code:\n",
    "```\n",
    "# pull file from git lfs system into local repo using any pointer files\n",
    "git lfs pull\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9Y2ymkF3KDW",
   "metadata": {
    "id": "w9Y2ymkF3KDW"
   },
   "source": [
    "## External Data Sources\n",
    "\n",
    "* [Persuade PII Dataset](https://www.kaggle.com/datasets/thedrcat/persuade-pii-dataset?rvi=1)\n",
    "  * Essays from Persuade corpus, modified with synthetic PII data and corresponding labels. It was filtered for essays that contain tokens that are relevant to competition.\n",
    "\n",
    "* [PII | External Dataset](https://www.kaggle.com/datasets/alejopaullier/pii-external-dataset?rvi=1)\n",
    "  * This is an LLM-generated external dataset that contains generated texts with their corresponding annotated labels in the required competition format.\n",
    "\n",
    "* [NEW DATASET PII Data Detection](https://www.kaggle.com/datasets/cristaliss/new-dataset-pii-data-detection?rvi=1)\n",
    "  * This dataset is a modified version of the official training which have the following changes: Revamped Labels, Token Transformation, and Token indexing\n",
    "\n",
    "* [PII Detection Dataset (GPT)](https://www.kaggle.com/datasets/pjmathematician/pii-detection-dataset-gpt)\n",
    "  * Personal data was created using python Faker package, which was then fed into the LLM to write an essay on. Overall, it contains 2000 gpt - generated essays and corresponding competition entities used in the essay.\n",
    "\n",
    "* [AI4privacy-PII](https://www.kaggle.com/datasets/verracodeguacas/ai4privacy-pii)\n",
    "  * The dataset is crafted using proprietary algorithms, ensuring the creation of synthetic data that avoids privacy violations. The data is meticulously curated with human-in-the-loop validation, ensuring both relevance and quality. It serves a crucial role in addressing the growing concerns around personal data security in AI applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sh7s_CBjbahT",
   "metadata": {
    "id": "Sh7s_CBjbahT"
   },
   "source": [
    "## Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "TP4-5t-sbcdn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:25:16.931261100Z",
     "start_time": "2024-02-05T00:25:16.875240500Z"
    },
    "id": "TP4-5t-sbcdn"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import spacy as sp\n",
    "    import re\n",
    "except DeprecationWarning:\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5flL5Dcfbeij",
   "metadata": {
    "id": "5flL5Dcfbeij"
   },
   "source": [
    "## Loading Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_goOMIO_blf8",
   "metadata": {
    "id": "_goOMIO_blf8"
   },
   "source": [
    "### Official training data\n",
    "\n",
    "Only load into notebook after pulling from git LFS (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "g1ogxxEqbjHk",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:24:01.929431500Z",
     "start_time": "2024-02-05T00:24:01.914405100Z"
    },
    "id": "g1ogxxEqbjHk"
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_json(\"../Datasets/Official/train.json\")\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7ZDz4fWbuoC",
   "metadata": {
    "id": "B7ZDz4fWbuoC"
   },
   "source": [
    "### Official testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "g81NUyTHbtaA",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:24:01.960053300Z",
     "start_time": "2024-02-05T00:24:01.929431500Z"
    },
    "id": "g81NUyTHbtaA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>Cheese Startup - Learning Launch ​by Eladio Am...</td>\n",
       "      <td>[Cheese, Startup, -, Learning, Launch, ​by, El...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93</td>\n",
       "      <td>Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...</td>\n",
       "      <td>[Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...</td>\n",
       "      <td>[True, False, False, False, False, False, True...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104</td>\n",
       "      <td>Storytelling  The Path to Innovation\\n\\nDr Sak...</td>\n",
       "      <td>[Storytelling,  , The, Path, to, Innovation, \\...</td>\n",
       "      <td>[True, False, True, True, True, False, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>Reflection – Learning Launch\\n\\nFrancisco Ferr...</td>\n",
       "      <td>[Reflection, –, Learning, Launch, \\n\\n, Franci...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123</td>\n",
       "      <td>Gandhi Institute of Technology and Management ...</td>\n",
       "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "5        86  Cheese Startup - Learning Launch ​by Eladio Am...   \n",
       "6        93  Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...   \n",
       "7       104  Storytelling  The Path to Innovation\\n\\nDr Sak...   \n",
       "8       112  Reflection – Learning Launch\\n\\nFrancisco Ferr...   \n",
       "9       123  Gandhi Institute of Technology and Management ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "5  [Cheese, Startup, -, Learning, Launch, ​by, El...   \n",
       "6  [Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...   \n",
       "7  [Storytelling,  , The, Path, to, Innovation, \\...   \n",
       "8  [Reflection, –, Learning, Launch, \\n\\n, Franci...   \n",
       "9  [Gandhi, Institute, of, Technology, and, Manag...   \n",
       "\n",
       "                                 trailing_whitespace  \n",
       "0  [True, True, True, True, False, False, True, F...  \n",
       "1  [True, False, False, True, True, False, False,...  \n",
       "2  [True, False, False, True, True, False, False,...  \n",
       "3  [True, True, True, False, False, True, False, ...  \n",
       "4  [False, False, False, False, False, False, Fal...  \n",
       "5  [True, True, True, True, True, True, True, Fal...  \n",
       "6  [True, False, False, False, False, False, True...  \n",
       "7  [True, False, True, True, True, False, False, ...  \n",
       "8  [True, True, True, False, False, True, False, ...  \n",
       "9  [True, True, True, True, True, True, False, Tr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json(\"../Datasets/Official/test.json\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8jWiYTLU1yF9",
   "metadata": {
    "id": "8jWiYTLU1yF9"
   },
   "source": [
    "## Cleaning\n",
    "To have some uniform input, each source dataframe needs to have a list of tokens from of the source text located in each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I1NxYq9KeUL4",
   "metadata": {
    "id": "I1NxYq9KeUL4"
   },
   "source": [
    "### Official training dataset\n",
    "Verify that there are no rows with any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:24:03.718803900Z",
     "start_time": "2024-02-05T00:24:03.691566400Z"
    },
    "collapsed": true,
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "# df_train[df_train.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YD43I84iecuM",
   "metadata": {
    "id": "YD43I84iecuM"
   },
   "source": [
    "### Official test dataset\n",
    "Verify that there are no rows with any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Z5eMI7UHecTu",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T00:24:03.732975100Z",
     "start_time": "2024-02-05T00:24:03.708833300Z"
    },
    "id": "Z5eMI7UHecTu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [document, full_text, tokens, trailing_whitespace]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7007b1",
   "metadata": {},
   "source": [
    "# Building the model framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd3d9d",
   "metadata": {},
   "source": [
    "### Loading and Cleaning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import re\n",
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af4e18",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "This section does initial configuration, loading our the bert pretained model that we use, as well as setting up hyper parameters like `EPOCHS` and `LEARNING_RATE`"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, platform, model_name, pretrained_model_name):\n",
    "        # platform = 'Kaggle'# \n",
    "        if platform == 'Kaggle':\n",
    "            pretrained_model = '../input/huggingface-bert/' + pretrained_model_name + '/'\n",
    "            train_path = 'path_TBD/train.json'\n",
    "            # test_path = ''\n",
    "            model_path = 'path_TBD/' + model_name\n",
    "        elif platform == 'local':\n",
    "            model_path = '../models/bert_models/' + model_name\n",
    "        \n",
    "        self.config = {\n",
    "            'MAX_LEN': 128,\n",
    "            'TRAIN_BATCH_SIZE': 4,\n",
    "            'VALID_BATCH_SIZE': 2,\n",
    "            'EPOCHS': 1,\n",
    "            'LEARNING_RATE':1e-5,\n",
    "            'MAX_GRAD_NORM': 10,\n",
    "            'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            # 'device': 'cpu',\n",
    "            'model_path': model_path,\n",
    "            'pretrained_model': pretrained_model_name,\n",
    "            'tokenizer': BertTokenizerFast.from_pretrained(pretrained_model_name)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9881cf6aae3952c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bf9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'local'\n",
    "pretrainend_model_name = 'bert-large-cased'\n",
    "model_num = 1\n",
    "model_name = 'model' + model_num + '_' + pretrainend_model_name +'.bin'\n",
    "\n",
    "config = Config(platform,model_name, pretrainend_model_name).config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c39bf",
   "metadata": {},
   "source": [
    "Requires:\n",
    "```git lfs track \"*.safetensors\"```\n",
    "to clone model from github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d309cae",
   "metadata": {},
   "source": [
    "If using IDE, Run \n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "in the bash to install the english spacy pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2613653",
   "metadata": {},
   "source": [
    "## Official Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5cd16",
   "metadata": {},
   "source": [
    "### Data and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a8f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>22678</td>\n",
       "      <td>EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...</td>\n",
       "      <td>[EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...</td>\n",
       "      <td>[True, True, True, False, False, True, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6803</th>\n",
       "      <td>22679</td>\n",
       "      <td>Why Mind Mapping?\\n\\nMind maps are graphical r...</td>\n",
       "      <td>[Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...</td>\n",
       "      <td>[True, True, False, False, False, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>22681</td>\n",
       "      <td>Challenge\\n\\nSo, a few months back, I had chos...</td>\n",
       "      <td>[Challenge, \\n\\n, So, ,, a, few, months, back,...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>22684</td>\n",
       "      <td>Brainstorming\\n\\nChallenge &amp; Selection\\n\\nBrai...</td>\n",
       "      <td>[Brainstorming, \\n\\n, Challenge, &amp;, Selection,...</td>\n",
       "      <td>[False, False, True, True, False, False, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>22687</td>\n",
       "      <td>Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...</td>\n",
       "      <td>[Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                          full_text  \\\n",
       "0            7  Design Thinking for innovation reflexion-Avril...   \n",
       "1           10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2           16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3           20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4           56  Assignment:  Visualization Reflection  Submitt...   \n",
       "...        ...                                                ...   \n",
       "6802     22678  EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...   \n",
       "6803     22679  Why Mind Mapping?\\n\\nMind maps are graphical r...   \n",
       "6804     22681  Challenge\\n\\nSo, a few months back, I had chos...   \n",
       "6805     22684  Brainstorming\\n\\nChallenge & Selection\\n\\nBrai...   \n",
       "6806     22687  Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Design, Thinking, for, innovation, reflexion,...   \n",
       "1     [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2     [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3     [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4     [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "...                                                 ...   \n",
       "6802  [EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...   \n",
       "6803  [Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...   \n",
       "6804  [Challenge, \\n\\n, So, ,, a, few, months, back,...   \n",
       "6805  [Brainstorming, \\n\\n, Challenge, &, Selection,...   \n",
       "6806  [Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "0     [True, True, True, True, False, False, True, F...   \n",
       "1     [True, False, False, True, True, False, False,...   \n",
       "2     [True, False, False, True, True, False, False,...   \n",
       "3     [True, True, True, False, False, True, False, ...   \n",
       "4     [False, False, False, False, False, False, Fal...   \n",
       "...                                                 ...   \n",
       "6802  [True, True, True, False, False, True, True, F...   \n",
       "6803  [True, True, False, False, False, True, True, ...   \n",
       "6804  [False, False, False, True, True, True, True, ...   \n",
       "6805  [False, False, True, True, False, False, True,...   \n",
       "6806  [True, False, False, False, False, True, True,...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1     [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2     [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3     [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n",
       "...                                                 ...  \n",
       "6802  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6803  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6804  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6805  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "6806  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[6807 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_json(\"../Datasets/Official/train.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[0;32m      2\u001B[0m c \u001B[38;5;241m=\u001B[39m Counter()\n\u001B[1;32m----> 3\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m line: c\u001B[38;5;241m.\u001B[39mupdate(line\u001B[38;5;241m.\u001B[39mlabels), axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m c_pii \u001B[38;5;241m=\u001B[39m c\u001B[38;5;241m.\u001B[39mmost_common()[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m      5\u001B[0m c_key, c_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mc_pii)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "df.apply(lambda line: c.update(line.labels), axis = 1)\n",
    "c_pii = c.most_common()[1:]\n",
    "c_key, c_val = zip(*c_pii)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T21:37:48.567355900Z",
     "start_time": "2024-03-18T21:37:46.716099Z"
    }
   },
   "id": "0713875d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B-NAME_STUDENT', 1365),\n",
       " ('I-NAME_STUDENT', 1096),\n",
       " ('B-URL_PERSONAL', 110),\n",
       " ('B-ID_NUM', 78),\n",
       " ('B-EMAIL', 39),\n",
       " ('I-STREET_ADDRESS', 20),\n",
       " ('I-PHONE_NUM', 15),\n",
       " ('B-USERNAME', 6),\n",
       " ('B-PHONE_NUM', 6),\n",
       " ('B-STREET_ADDRESS', 2),\n",
       " ('I-URL_PERSONAL', 1),\n",
       " ('I-ID_NUM', 1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_pii"
   ],
   "metadata": {},
   "id": "77e0cb9b",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Showing frequency of each label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ddf4a1cca71fe03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.barh(c_key, c_val)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5916475fecd838"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d64dfba543d9fcf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ed9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-NAME_STUDENT': 1,\n",
       " 'I-NAME_STUDENT': 2,\n",
       " 'B-URL_PERSONAL': 3,\n",
       " 'B-EMAIL': 4,\n",
       " 'B-ID_NUM': 5,\n",
       " 'I-URL_PERSONAL': 6,\n",
       " 'B-USERNAME': 7,\n",
       " 'B-PHONE_NUM': 8,\n",
       " 'I-PHONE_NUM': 9,\n",
       " 'B-STREET_ADDRESS': 10,\n",
       " 'I-STREET_ADDRESS': 11,\n",
       " 'I-ID_NUM': 12}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(c.keys())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(c.keys())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed8113",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we make sure that the length of the tokens and the length of the labels are the same for each document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a44435d6a117f78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_usable = df.iloc[df[~(df.tokens.apply(len) != df.labels.apply(len))].index]\n",
    "1-(len(df_usable))/len(df.document)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb0e86825acf3c89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replaces unique spaces (like NBSPs) in the documents with uft-8 spaces"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f73041517d5e8df6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c4faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06184809754664311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern = re.compile('\\xa0|\\uf0b7|\\u200b')\n",
    "df.loc[:,'full_text'] = df.loc[:,'full_text'].replace(pattern, ' ')\n",
    "df.loc[:,'tokens'] = df.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern,tok)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723c782",
   "metadata": {},
   "source": [
    "Here we chunk the token and label arrays of the texts into smaller arrays based `MAX_LEN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48777ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smaller_inputs(dataframe):\n",
    "    df_out = pd.DataFrame(columns = ['tokens','labels'])\n",
    "    counter = 0\n",
    "    max_len = config['MAX_LEN']\n",
    "    \n",
    "    for _,line in dataframe.iterrows():\n",
    "        tokens = line.tokens\n",
    "        labels = line.labels\n",
    "        items = range(0,len(tokens),max_len)\n",
    "        \n",
    "        for i in items:\n",
    "            df_out.at[counter,'tokens'] = tokens[i:i+max_len]\n",
    "            df_out.at[counter,'labels'] = labels[i:i+max_len]\n",
    "            counter += 1\n",
    "            \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73aaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[significant, material, investment, and, can, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[starting, point,  , generates, ideas, /, work...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, series,  , of, questions, according, to,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[images, and, interconnections, ., This, secon...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [significant, material, investment, and, can, ...   \n",
       "2  [starting, point,  , generates, ideas, /, work...   \n",
       "3  [the, series,  , of, questions, according, to,...   \n",
       "4  [images, and, interconnections, ., This, secon...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_model_input = make_smaller_inputs(df_usable)\n",
    "df_model_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b8c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(df_model_input.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e261b43",
   "metadata": {},
   "source": [
    "### Creating the training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_model_input.sample(n=10000), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e1958",
   "metadata": {},
   "source": [
    "### Formatting split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b1ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[on, the, proper, to, identify, Oversight, Org...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, important, we, must, be, when, choosing,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2019, \\n\\n, •,  , The, 4500, managers, who, n...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[very, important, to, reinforce, your, underst...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[broke, up, with, her, and, it, still, pains, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>[step, and, help, us, to, publish, our, produc...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>[Challenge, \\n\\n, I, am, part, of, the, produc...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>[of, their, ideas, .,    , Application, :,  , ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>[,, since, here, we, could, simply, just, summ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>[made, a, vast, library, of, compounds, ., \\n\\...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [on, the, proper, to, identify, Oversight, Org...   \n",
       "1     [how, important, we, must, be, when, choosing,...   \n",
       "2     [2019, \\n\\n, •,  , The, 4500, managers, who, n...   \n",
       "3     [very, important, to, reinforce, your, underst...   \n",
       "4     [broke, up, with, her, and, it, still, pains, ...   \n",
       "...                                                 ...   \n",
       "7995  [step, and, help, us, to, publish, our, produc...   \n",
       "7996  [Challenge, \\n\\n, I, am, part, of, the, produc...   \n",
       "7997  [of, their, ideas, .,    , Application, :,  , ...   \n",
       "7998  [,, since, here, we, could, simply, just, summ...   \n",
       "7999  [made, a, vast, library, of, compounds, ., \\n\\...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "7995  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7996  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7997  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7998  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "7999  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.reset_index(drop = True, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ , what, woww, and, what, works, ., \\n\\n, Ins...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Reflection, -, Storytelling, \\n\\n, Challenge,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cover, and, content, it, ’s, a, most, challen...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[test, new, ideas, drive, from, information, g...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[is, also, fact, ., Therefore, ,, I, believe, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[clear, picture, of, what, we, have, and, what...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[had, find, out, what, was, the, big,  , probl...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[a, more, intimate, way, ., We, are, not, just...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[here, was, a, digital, shared, platform, to, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[we, needed, to, make, ., For, future, launch,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [ , what, woww, and, what, works, ., \\n\\n, Ins...   \n",
       "1     [Reflection, -, Storytelling, \\n\\n, Challenge,...   \n",
       "2     [cover, and, content, it, ’s, a, most, challen...   \n",
       "3     [test, new, ideas, drive, from, information, g...   \n",
       "4     [is, also, fact, ., Therefore, ,, I, believe, ...   \n",
       "...                                                 ...   \n",
       "1995  [clear, picture, of, what, we, have, and, what...   \n",
       "1996  [had, find, out, what, was, the, big,  , probl...   \n",
       "1997  [a, more, intimate, way, ., We, are, not, just...   \n",
       "1998  [here, was, a, digital, shared, platform, to, ...   \n",
       "1999  [we, needed, to, make, ., For, future, launch,...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "...                                                 ...  \n",
       "1995  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1996  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1997  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1998  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1999  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.reset_index(drop = True, inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e75cd",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b652f99",
   "metadata": {},
   "source": [
    "adapted from \n",
    "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=Eh3ckSO0YMZW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61724112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        tokens = self.data.tokens[index]\n",
    "        word_labels = self.data.labels[index]\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(tokens,\n",
    "                                  is_split_into_words=True,\n",
    "                                  return_offsets_mapping=True,\n",
    "                                  padding='max_length',\n",
    "                                  truncation=True,\n",
    "                                  max_length=self.max_len)\n",
    "\n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [ labels_to_ids[label] for label in word_labels]\n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "            if mapping[0] == 0 and mapping[1] != 0:\n",
    "                # overwrite label\n",
    "                encoded_labels[idx] = labels[i]\n",
    "                i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset(df_train, config['tokenizer'], config['MAX_LEN'])\n",
    "testing_set = dataset(df_test, config['tokenizer'], config['MAX_LEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 10351,   794,  1109, 10181,  1568, 11493,  1150,  1444,  3972,\n",
       "          1132,  1155,  1166,  1103,  1362,  1105,  2936,  1483,   794,  1247,\n",
       "          1110,  1136,  4788,  1111,   786,  1339,  1106,  1339,   787,  2013,\n",
       "           794, 23070,  1116,  1132,  3600,   117,  1105,  1412,  1159, 27135,\n",
       "          1106,  4821,  1147,  2209,  1110,  2609,   124,   119, 10997, 27258,\n",
       "          9741, 13821, 24805,   131,  1752,   117,  1606,  7934,  2713,   113,\n",
       "         18012,   125,   114,   117,   146,  1899,  1114,  1317,  2501, 26027,\n",
       "           117, 12859, 16811, 21773, 16409, 17786,  1116,   113, 19293,  2036,\n",
       "           787,   188,   114,  1105, 11493,  1150,  1138,  1640,  1151,  3972,\n",
       "          1113,  1103,  1671,  1449,   119,  2397, 13032, 11646,  1114,  1103,\n",
       "         19293,  2036,   787,   188,  1105, 13942,  1104,  1103,  1933,   117,\n",
       "          1195,  1138,   124,  3209, 19129,  1106,  9474,  1412,  4506,   119,\n",
       "           146,  2063,  1103,  9681, 26738,  1902,  1111,   102]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_set[2][\"input_ids\"].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is an example array that the model would use to train written back into an array of strings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab3c8528dc0258b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7333d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       -100\n",
      "on          0\n",
      "the         0\n",
      "proper      0\n",
      "to          0\n",
      "identify    0\n",
      "Over        0\n",
      "##sight     -100\n",
      "Organizations  0\n",
      ",           0\n",
      "resembling  0\n",
      "Congress    0\n",
      ",           0\n",
      "GA          0\n",
      "##O         -100\n",
      ",           0\n",
      "labour      0\n",
      "unions      0\n",
      ",           0\n",
      "support     0\n",
      "groups      0\n",
      ",           0\n",
      "and         0\n",
      "alternative  0\n",
      "entities    0\n",
      "that        0\n",
      "will        0\n",
      "add         0\n",
      "constraints  0\n",
      "to          0\n",
      "however     0\n",
      "the         0\n",
      "organization  0\n",
      "operates    0\n",
      ".           0\n",
      "The         0\n",
      "straw       0\n",
      "man         0\n",
      "graphic     0\n",
      "is          0\n",
      "easy        0\n",
      ",           0\n",
      "victim      0\n",
      "##ization   -100\n",
      "simple      0\n",
      "shapes      0\n",
      "and         0\n",
      "icons       0\n",
      "obtain      0\n",
      "##able      -100\n",
      "in          0\n",
      "V           0\n",
      "##isi       -100\n",
      "##o         -100\n",
      "or          0\n",
      "on          0\n",
      "the         0\n",
      "Internet    0\n",
      ".           0\n",
      "If          0\n",
      "the         0\n",
      "front       0\n",
      "-           0\n",
      "stage       0\n",
      "/           0\n",
      "back        0\n",
      "-           0\n",
      "stage       0\n",
      "read        0\n",
      "does        0\n",
      "n           0\n",
      "’           -100\n",
      "t           -100\n",
      "work        0\n",
      ",           0\n",
      "then        0\n",
      "i           0\n",
      "'           0\n",
      "ll          -100\n",
      "produce     0\n",
      "a           0\n",
      "unique      0\n",
      "kind        0\n",
      "of          0\n",
      "visual      0\n",
      ",           0\n",
      "either      0\n",
      "supported   0\n",
      "a           0\n",
      "high        0\n",
      "-           0\n",
      "level       0\n",
      "method      0\n",
      "flow        0\n",
      "with        0\n",
      "swim        0\n",
      "lanes       0\n",
      "for         0\n",
      "various     0\n",
      "stakeholders  0\n",
      ",           0\n",
      "or          0\n",
      "another     0\n",
      "format      0\n",
      ".           0\n",
      "For         0\n",
      "the         0\n",
      "activity    0\n",
      ",           0\n",
      "I           0\n",
      "'           0\n",
      "ll          -100\n",
      "divide      0\n",
      "the         0\n",
      "stakeholders  0\n",
      "into        0\n",
      "teams       0\n",
      "of          0\n",
      "5           0\n",
      "-           0\n",
      "6           0\n",
      "participants  0\n",
      "every       0\n",
      "representing  0\n",
      "a           0\n",
      "unique      0\n",
      "organization  0\n",
      "[SEP]       -100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(config['tokenizer'].convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "    print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb12963",
   "metadata": {},
   "source": [
    "Setting training and testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': config[\"TRAIN_BATCH_SIZE\"],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': config[\"VALID_BATCH_SIZE\"],\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0\n",
    "               }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we initialize our pretrained BERT token classification model with random weights and biases"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0267bc3a2ed9817"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c6df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(config['pretrained_model'], num_labels=len(labels_to_ids))\n",
    "model.to(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746eee6b",
   "metadata": {},
   "source": [
    "expected loss of inital model is \n",
    "-ln(1/(# of classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae0013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5649493574615367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-np.log(1/len(labels_to_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb99ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5633, grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(config['device'])\n",
    "attention_mask = attention_mask.to(config['device'])\n",
    "labels = labels.to(config['device'])\n",
    "\n",
    "outputs = model(input_ids.long(), attention_mask=attention_mask.long(), labels=labels.long())\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172f774",
   "metadata": {},
   "source": [
    "Limit of my comprehension as of 3/7"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building training loop\n",
    "\n",
    "Below we define the optimizer algorthm (Adam) and the loss evaluation function. Then we defined the training loop function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71a09963f4f23c33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8727b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "        labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids.long(), attention_mask=mask.long(), labels=labels.long())\n",
    "        loss = outputs[0]\n",
    "        tr_logits = outputs[1]\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "\n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=config['MAX_GRAD_NORM']\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a47529",
   "metadata": {},
   "source": [
    "### Determine whether to run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        print(f\"Training epoch: {epoch + 1}\")\n",
    "        train(epoch)\n",
    "    run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fc802",
   "metadata": {},
   "source": [
    "KeyError: 9637\n",
    "KeyError: 2326\n",
    "KeyError: 10126"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This creates a directory to save and store trained models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f821dcc56eaae2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ab661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = config['model_path']\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# save vocabulary of the tokenizer\n",
    "config['tokenizer'].save_vocabulary(directory)\n",
    "# save the model weights and its configuration file\n",
    "save_model = False\n",
    "if save_model:  \n",
    "    model.save_pretrained(directory)\n",
    "    print('All files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668cdb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../models/bert_models/model2bert-large-cased.bin does not appear to have a file named config.json. Checkout 'https://huggingface.co/../models/bert_models/model2bert-large-cased.bin/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)\n",
      "Cell \u001B[1;32mIn[101], line 1\u001B[0m\n",
      "\u001B[1;32m----> 1\u001B[0m model1 \u001B[38;5;241m=\u001B[39m \u001B[43mBertForTokenClassification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_path\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlabels_to_ids\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mto(config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\n",
      "File \u001B[1;32m~\\lib\\site-packages\\transformers\\modeling_utils.py:2981\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m   2979\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n",
      "\u001B[0;32m   2980\u001B[0m     config_path \u001B[38;5;241m=\u001B[39m config \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m pretrained_model_name_or_path\n",
      "\u001B[1;32m-> 2981\u001B[0m     config, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mconfig_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n",
      "\u001B[0;32m   2982\u001B[0m         config_path,\n",
      "\u001B[0;32m   2983\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n",
      "\u001B[0;32m   2984\u001B[0m         return_unused_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
      "\u001B[0;32m   2985\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n",
      "\u001B[0;32m   2986\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n",
      "\u001B[0;32m   2987\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n",
      "\u001B[0;32m   2988\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n",
      "\u001B[0;32m   2989\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n",
      "\u001B[0;32m   2990\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n",
      "\u001B[0;32m   2991\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n",
      "\u001B[0;32m   2992\u001B[0m         _from_auto\u001B[38;5;241m=\u001B[39mfrom_auto_class,\n",
      "\u001B[0;32m   2993\u001B[0m         _from_pipeline\u001B[38;5;241m=\u001B[39mfrom_pipeline,\n",
      "\u001B[0;32m   2994\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n",
      "\u001B[0;32m   2995\u001B[0m     )\n",
      "\u001B[0;32m   2996\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;32m   2997\u001B[0m     \u001B[38;5;66;03m# In case one passes a config to `from_pretrained` + \"attn_implementation\"\u001B[39;00m\n",
      "\u001B[0;32m   2998\u001B[0m     \u001B[38;5;66;03m# override the `_attn_implementation` attribute to `attn_implementation` of the kwargs\u001B[39;00m\n",
      "\u001B[1;32m   (...)\u001B[0m\n",
      "\u001B[0;32m   3002\u001B[0m     \u001B[38;5;66;03m# we pop attn_implementation from the kwargs but this handles the case where users\u001B[39;00m\n",
      "\u001B[0;32m   3003\u001B[0m     \u001B[38;5;66;03m# passes manually the config to `from_pretrained`.\u001B[39;00m\n",
      "\u001B[0;32m   3004\u001B[0m     config \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(config)\n",
      "\n",
      "File \u001B[1;32m~\\lib\\site-packages\\transformers\\configuration_utils.py:604\u001B[0m, in \u001B[0;36mPretrainedConfig.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001B[0m\n",
      "\u001B[0;32m    600\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrevision\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m revision\n",
      "\u001B[0;32m    602\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_set_token_in_kwargs(kwargs, token)\n",
      "\u001B[1;32m--> 604\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type:\n",
      "\u001B[0;32m    606\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n",
      "\u001B[0;32m    607\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are using a model of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to instantiate a model of type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;32m    608\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;32m    609\u001B[0m     )\n",
      "\n",
      "File \u001B[1;32m~\\lib\\site-packages\\transformers\\configuration_utils.py:633\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n",
      "\u001B[0;32m    631\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n",
      "\u001B[0;32m    632\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n",
      "\u001B[1;32m--> 633\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;32m    634\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict:\n",
      "\u001B[0;32m    635\u001B[0m     original_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\n",
      "File \u001B[1;32m~\\lib\\site-packages\\transformers\\configuration_utils.py:688\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n",
      "\u001B[0;32m    684\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME)\n",
      "\u001B[0;32m    686\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;32m    687\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n",
      "\u001B[1;32m--> 688\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n",
      "\u001B[0;32m    689\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    690\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n",
      "\u001B[0;32m    701\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;32m    702\u001B[0m     commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n",
      "\u001B[0;32m    704\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001B[39;00m\n",
      "\u001B[0;32m    705\u001B[0m     \u001B[38;5;66;03m# the original exception.\u001B[39;00m\n",
      "\n",
      "File \u001B[1;32m~\\lib\\site-packages\\transformers\\utils\\hub.py:369\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n",
      "\u001B[0;32m    367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n",
      "\u001B[0;32m    368\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001B[1;32m--> 369\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n",
      "\u001B[0;32m    370\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;32m    371\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;32m    372\u001B[0m         )\n",
      "\u001B[0;32m    373\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;32m    374\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\n",
      "\u001B[1;31mOSError\u001B[0m: ../models/bert_models/model2bert-large-cased.bin does not appear to have a file named config.json. Checkout 'https://huggingface.co/../models/bert_models/model2bert-large-cased.bin/main' for available files."
     ]
    }
   ],
   "source": [
    "model1 = BertForTokenClassification.from_pretrained(config['model_path'], num_labels=len(labels_to_ids))\n",
    "model1.to(config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation\n",
    "\n",
    "Below we validate the model by testing it with the test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e6bf1b0a4a50590"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101427a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "            labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids.long(), attention_mask=mask.long(), labels=labels.long())\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            eval_logits = outputs[1]\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "            \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = valid(model1, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb51181",
   "metadata": {},
   "source": [
    "About 50% for getting student names correct, 0% for the others"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
