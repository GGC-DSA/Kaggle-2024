{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chcr1ibHHbS_",
   "metadata": {
    "id": "chcr1ibHHbS_"
   },
   "source": [
    "# Identifying PII in Student Essays\n",
    "## Project Summary\n",
    "The Kaggle Competition we are participating in is the [PII Data Detection hosted by The Learning Agency Lab](https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/overview). The goal of this competition is to develop a model that detects sensitive personally identifiable information (PII) in student writing. This is necessary to screen and clean educational data so that when released to the public for analysis and archival, the students' risk are mitigated.\n",
    "\n",
    "## Cloning Repo\n",
    "Because one of the files is larger than 100MiB, the file could not be uploaded directly to the github repo. The solution found was using git large file system to hold the file and upload the git lfs pointer file in the place of the json.\n",
    "\n",
    "Git Bash Code:\n",
    "```\n",
    "# install git lfs\n",
    "git lfs install\n",
    "\n",
    "# start file tracking for git lfs in the repo\n",
    "git lfs track \"*.json\"\n",
    "\n",
    "# stage/commit/push training json\n",
    "git add train.json\n",
    "git commit -m \"add train.json\"\n",
    "git push\n",
    "```\n",
    "After cloning the repo locally, it clones the git lfs pointer file not the data file.\n",
    "\n",
    "Git Bash Code:\n",
    "```\n",
    "# pull file from git lfs system into local repo using any pointer files\n",
    "git lfs pull\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9Y2ymkF3KDW",
   "metadata": {
    "id": "w9Y2ymkF3KDW"
   },
   "source": [
    "## External Data Sources\n",
    "\n",
    "* [Persuade PII Dataset](https://www.kaggle.com/datasets/thedrcat/persuade-pii-dataset?rvi=1)\n",
    "  * Essays from Persuade corpus, modified with synthetic PII data and corresponding labels. It was filtered for essays that contain tokens that are relevant to competition.\n",
    "\n",
    "* [PII | External Dataset](https://www.kaggle.com/datasets/alejopaullier/pii-external-dataset?rvi=1)\n",
    "  * This is an LLM-generated external dataset that contains generated texts with their corresponding annotated labels in the required competition format.\n",
    "\n",
    "* [NEW DATASET PII Data Detection](https://www.kaggle.com/datasets/cristaliss/new-dataset-pii-data-detection?rvi=1)\n",
    "  * This dataset is a modified version of the official training which have the following changes: Revamped Labels, Token Transformation, and Token indexing\n",
    "\n",
    "* [PII Detection Dataset (GPT)](https://www.kaggle.com/datasets/pjmathematician/pii-detection-dataset-gpt)\n",
    "  * Personal data was created using python Faker package, which was then fed into the LLM to write an essay on. Overall, it contains 2000 gpt - generated essays and corresponding competition entities used in the essay.\n",
    "\n",
    "* [AI4privacy-PII](https://www.kaggle.com/datasets/verracodeguacas/ai4privacy-pii)\n",
    "  * The dataset is crafted using proprietary algorithms, ensuring the creation of synthetic data that avoids privacy violations. The data is meticulously curated with human-in-the-loop validation, ensuring both relevance and quality. It serves a crucial role in addressing the growing concerns around personal data security in AI applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sh7s_CBjbahT",
   "metadata": {
    "id": "Sh7s_CBjbahT"
   },
   "source": [
    "## Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "TP4-5t-sbcdn",
   "metadata": {
    "id": "TP4-5t-sbcdn",
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:40.533034Z",
     "start_time": "2024-04-18T01:10:40.014238900Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mspacy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msp\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import spacy as sp\n",
    "    import re\n",
    "    from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from datasets import Dataset\n",
    "    import evaluate\n",
    "except DeprecationWarning:\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5flL5Dcfbeij",
   "metadata": {
    "id": "5flL5Dcfbeij"
   },
   "source": [
    "## Loading Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_goOMIO_blf8",
   "metadata": {
    "id": "_goOMIO_blf8"
   },
   "source": [
    "### Official training data\n",
    "\n",
    "Only load into notebook after pulling from git LFS (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "g1ogxxEqbjHk",
   "metadata": {
    "id": "g1ogxxEqbjHk",
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:42.242682Z",
     "start_time": "2024-04-18T01:10:40.536558800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      document                                          full_text  \\\n0            7  Design Thinking for innovation reflexion-Avril...   \n1           10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n2           16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n3           20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n4           56  Assignment:  Visualization Reflection  Submitt...   \n...        ...                                                ...   \n6802     22678  EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...   \n6803     22679  Why Mind Mapping?\\n\\nMind maps are graphical r...   \n6804     22681  Challenge\\n\\nSo, a few months back, I had chos...   \n6805     22684  Brainstorming\\n\\nChallenge & Selection\\n\\nBrai...   \n6806     22687  Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...   \n\n                                                 tokens  \\\n0     [Design, Thinking, for, innovation, reflexion,...   \n1     [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n2     [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n3     [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n4     [Assignment, :,   , Visualization,  , Reflecti...   \n...                                                 ...   \n6802  [EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...   \n6803  [Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...   \n6804  [Challenge, \\n\\n, So, ,, a, few, months, back,...   \n6805  [Brainstorming, \\n\\n, Challenge, &, Selection,...   \n6806  [Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...   \n\n                                    trailing_whitespace  \\\n0     [True, True, True, True, False, False, True, F...   \n1     [True, False, False, True, True, False, False,...   \n2     [True, False, False, True, True, False, False,...   \n3     [True, True, True, False, False, True, False, ...   \n4     [False, False, False, False, False, False, Fal...   \n...                                                 ...   \n6802  [True, True, True, False, False, True, True, F...   \n6803  [True, True, False, False, False, True, True, ...   \n6804  [False, False, False, True, True, True, True, ...   \n6805  [False, False, True, True, False, False, True,...   \n6806  [True, False, False, False, False, True, True,...   \n\n                                                 labels  \n0     [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n1     [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n2     [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n3     [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n4     [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n...                                                 ...  \n6802  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n6803  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n6804  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n6805  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n6806  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n\n[6807 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>full_text</th>\n      <th>tokens</th>\n      <th>trailing_whitespace</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>Design Thinking for innovation reflexion-Avril...</td>\n      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n      <td>[True, True, True, True, False, False, True, F...</td>\n      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n      <td>[True, True, True, False, False, True, False, ...</td>\n      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>Assignment:  Visualization Reflection  Submitt...</td>\n      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6802</th>\n      <td>22678</td>\n      <td>EXAMPLE – JOURNEY MAP\\n\\nTHE CHALLENGE    My w...</td>\n      <td>[EXAMPLE, –, JOURNEY, MAP, \\n\\n, THE, CHALLENG...</td>\n      <td>[True, True, True, False, False, True, True, F...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>6803</th>\n      <td>22679</td>\n      <td>Why Mind Mapping?\\n\\nMind maps are graphical r...</td>\n      <td>[Why, Mind, Mapping, ?, \\n\\n, Mind, maps, are,...</td>\n      <td>[True, True, False, False, False, True, True, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>6804</th>\n      <td>22681</td>\n      <td>Challenge\\n\\nSo, a few months back, I had chos...</td>\n      <td>[Challenge, \\n\\n, So, ,, a, few, months, back,...</td>\n      <td>[False, False, False, True, True, True, True, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>6805</th>\n      <td>22684</td>\n      <td>Brainstorming\\n\\nChallenge &amp; Selection\\n\\nBrai...</td>\n      <td>[Brainstorming, \\n\\n, Challenge, &amp;, Selection,...</td>\n      <td>[False, False, True, True, False, False, True,...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>6806</th>\n      <td>22687</td>\n      <td>Mind Mapping\\n\\nChallenge\\n\\nMy consulting tea...</td>\n      <td>[Mind, Mapping, \\n\\n, Challenge, \\n\\n, My, con...</td>\n      <td>[True, False, False, False, False, True, True,...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6807 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json(\"../Datasets/Official/train.json\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7ZDz4fWbuoC",
   "metadata": {
    "id": "B7ZDz4fWbuoC"
   },
   "source": [
    "### Official testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "g81NUyTHbtaA",
   "metadata": {
    "id": "g81NUyTHbtaA",
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:42.334017800Z",
     "start_time": "2024-04-18T01:10:42.217288700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   document                                          full_text  \\\n0         7  Design Thinking for innovation reflexion-Avril...   \n1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n4        56  Assignment:  Visualization Reflection  Submitt...   \n5        86  Cheese Startup - Learning Launch ​by Eladio Am...   \n6        93  Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...   \n7       104  Storytelling  The Path to Innovation\\n\\nDr Sak...   \n8       112  Reflection – Learning Launch\\n\\nFrancisco Ferr...   \n9       123  Gandhi Institute of Technology and Management ...   \n\n                                              tokens  \\\n0  [Design, Thinking, for, innovation, reflexion,...   \n1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n4  [Assignment, :,   , Visualization,  , Reflecti...   \n5  [Cheese, Startup, -, Learning, Launch, ​by, El...   \n6  [Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...   \n7  [Storytelling,  , The, Path, to, Innovation, \\...   \n8  [Reflection, –, Learning, Launch, \\n\\n, Franci...   \n9  [Gandhi, Institute, of, Technology, and, Manag...   \n\n                                 trailing_whitespace  \n0  [True, True, True, True, False, False, True, F...  \n1  [True, False, False, True, True, False, False,...  \n2  [True, False, False, True, True, False, False,...  \n3  [True, True, True, False, False, True, False, ...  \n4  [False, False, False, False, False, False, Fal...  \n5  [True, True, True, True, True, True, True, Fal...  \n6  [True, False, False, False, False, False, True...  \n7  [True, False, True, True, True, False, False, ...  \n8  [True, True, True, False, False, True, False, ...  \n9  [True, True, True, True, True, True, False, Tr...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>full_text</th>\n      <th>tokens</th>\n      <th>trailing_whitespace</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>Design Thinking for innovation reflexion-Avril...</td>\n      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n      <td>[True, True, True, True, False, False, True, F...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n      <td>[True, True, True, False, False, True, False, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>Assignment:  Visualization Reflection  Submitt...</td>\n      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>86</td>\n      <td>Cheese Startup - Learning Launch ​by Eladio Am...</td>\n      <td>[Cheese, Startup, -, Learning, Launch, ​by, El...</td>\n      <td>[True, True, True, True, True, True, True, Fal...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>93</td>\n      <td>Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...</td>\n      <td>[Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...</td>\n      <td>[True, False, False, False, False, False, True...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>104</td>\n      <td>Storytelling  The Path to Innovation\\n\\nDr Sak...</td>\n      <td>[Storytelling,  , The, Path, to, Innovation, \\...</td>\n      <td>[True, False, True, True, True, False, False, ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>112</td>\n      <td>Reflection – Learning Launch\\n\\nFrancisco Ferr...</td>\n      <td>[Reflection, –, Learning, Launch, \\n\\n, Franci...</td>\n      <td>[True, True, True, False, False, True, False, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>123</td>\n      <td>Gandhi Institute of Technology and Management ...</td>\n      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n      <td>[True, True, True, True, True, True, False, Tr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json(\"../Datasets/Official/test.json\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8jWiYTLU1yF9",
   "metadata": {
    "id": "8jWiYTLU1yF9"
   },
   "source": [
    "## Cleaning\n",
    "To have some uniform input, each source dataframe needs to have a list of tokens from of the source text located in each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I1NxYq9KeUL4",
   "metadata": {
    "id": "I1NxYq9KeUL4"
   },
   "source": [
    "### Official training dataset\n",
    "Verify that there are no rows with any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:42.430678400Z",
     "start_time": "2024-04-18T01:10:42.263931500Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train[df_train.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YD43I84iecuM",
   "metadata": {
    "id": "YD43I84iecuM"
   },
   "source": [
    "### Official test dataset\n",
    "Verify that there are no rows with any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Z5eMI7UHecTu",
   "metadata": {
    "id": "Z5eMI7UHecTu",
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:42.717954900Z",
     "start_time": "2024-04-18T01:10:42.279455300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [document, full_text, tokens, trailing_whitespace]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>full_text</th>\n      <th>tokens</th>\n      <th>trailing_whitespace</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7007b1",
   "metadata": {},
   "source": [
    "# Preparing Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd3d9d",
   "metadata": {},
   "source": [
    "### Loading and Cleaning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fe2971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:42.752028300Z",
     "start_time": "2024-04-18T01:10:42.296206600Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mspacy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy as sp\n",
    "import re\n",
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import cuda\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af4e18",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "This section does initial configuration, loading our the bert pretained model that we use, as well as setting up hyper parameters like `EPOCHS` and `LEARNING_RATE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df3a53",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.325014500Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, platform, model_name, pretrained_model_name):\n",
    "        # platform = 'Kaggle'# \n",
    "        if platform == 'Kaggle':\n",
    "            pretrained_model = '../input/huggingface-bert/' + pretrained_model_name + '/'\n",
    "            train_path = 'path_TBD/train.json'\n",
    "            # test_path = ''\n",
    "            model_path = 'path_TBD/' + model_name\n",
    "        elif platform == 'local':\n",
    "            model_path = '../models/bert_models/' + model_name\n",
    "        \n",
    "        self.config = {\n",
    "            'MAX_LEN': 128,\n",
    "            'TRAIN_BATCH_SIZE': 4,\n",
    "            'VALID_BATCH_SIZE': 2,\n",
    "            'EPOCHS': 1,\n",
    "            'LEARNING_RATE':1e-5,\n",
    "            'MAX_GRAD_NORM': 10,\n",
    "            'device': 'cuda' if cuda.is_available() else 'cpu',\n",
    "            # 'device': 'cpu',\n",
    "            'model_path': model_path,\n",
    "            'pretrained_model': pretrained_model_name,\n",
    "            'tokenizer': BertTokenizerFast.from_pretrained(pretrained_model_name),\n",
    "            'threshold': 0.9\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8bf9a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.328411300Z"
    }
   },
   "outputs": [],
   "source": [
    "platform = 'local'\n",
    "pretrainend_model_name = 'bert-base-cased'\n",
    "model_num = 1\n",
    "model_name = 'model' + str(model_num) + '-' + pretrainend_model_name +'.bin'\n",
    "\n",
    "config = Config(platform,model_name, pretrainend_model_name).config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c39bf",
   "metadata": {},
   "source": [
    "Requires:\n",
    "```git lfs track \"*.safetensors\"```\n",
    "to clone model from github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d309cae",
   "metadata": {},
   "source": [
    "If using IDE, Run \n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "in the bash to install the english spacy pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2613653",
   "metadata": {},
   "source": [
    "## Official Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5cd16",
   "metadata": {},
   "source": [
    "### Data and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a8f7e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.331795600Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../Datasets/Official/train.json\")\n",
    "df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e469b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.336301800Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[df.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8857b",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e84569",
   "metadata": {},
   "source": [
    "### Proportion of PII as a percentage of the text\n",
    "\n",
    "H0: The proportion of PII in each text is zero.​\n",
    "\n",
    "Ha: The proportion of PII in each text is not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d1db23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.341857800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = df['labels']\n",
    "\n",
    "non_o_values = df.apply(lambda line: sum(1 for x in line['labels'] if x != 'O')/ len(line['labels']), axis = 1)\n",
    "\n",
    "proportions_array = np.array(non_o_values)\n",
    "\n",
    "plt.hist(proportions_array, bins=20, color='blue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Proportion of PII Values in Text')\n",
    "plt.ylabel('Frequency (Log Scaled)')\n",
    "plt.yscale('log')\n",
    "plt.title('Distribution of PII Values in Text')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd2629",
   "metadata": {},
   "source": [
    "Since the p-value is below alpha (0.01) we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fc706",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.346579900Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "t_statistic, p_value = stats.ttest_1samp(proportions_array, 0)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77987c2f",
   "metadata": {},
   "source": [
    "### Proprtion of each type of PII\n",
    "\n",
    "H0: All PII have equal likelihood of appearing.​\n",
    "\n",
    "Ha: Name PII are more likely to appear.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713875d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.348942300Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "df.apply(lambda line: c.update(line.labels), axis = 1)\n",
    "c_pii = c.most_common()[1:]\n",
    "c_key, c_val = zip(*c_pii)\n",
    "plt.barh(c_key, c_val)\n",
    "# plt.ylabel('PII Labels', horizontalalignment='left')\n",
    "plt.title(\"Occurrences of PII Type in Text\")\n",
    "# plt.subplots_adjust(left=0.2)\n",
    "# plt.gca().get_yticklabels() # This gets the current y-axis tick labels\n",
    "pos = plt.gca().get_position()\n",
    "plt.gca().set_position([pos.x0 + 0.9, pos.y0 + 0.9, pos.width * 0.9, pos.height * 0.9])\n",
    "[tl.set_horizontalalignment('left') for tl in plt.gca().get_yticklabels()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a369b76",
   "metadata": {},
   "source": [
    "### Positional distribution of most popular PII\n",
    "\n",
    "H0: PII is evenly distributed across the length of an essay.​​\n",
    "\n",
    "Ha: PII is more likely to appear in the beginning of the essay.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05331079",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.353383400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates a dictionary for each position in the text (beginning, middle, and end)\n",
    "positions = {\n",
    "    'beginning': lambda x: x[:int(len(x)/3)],\n",
    "    'middle': lambda x: x[int(len(x)/3):int(-len(x)/3)],\n",
    "    'end': lambda x: x[int(-len(x)/3):-1]\n",
    "}\n",
    "\n",
    "label_counts = {pos: {} for pos in positions}\n",
    "for arr in df['labels']:\n",
    "    for pos, func in positions.items():\n",
    "            arr = func(arr)\n",
    "            for label in arr:\n",
    "                if label in label_counts[pos]:\n",
    "                        label_counts[pos][label] += 1\n",
    "                else:\n",
    "                        label_counts[pos][label] = 1\n",
    "\n",
    "\n",
    "beginning_labels = label_counts['beginning']\n",
    "middle_labels = label_counts['middle']\n",
    "end_labels = label_counts['end']\n",
    "\n",
    "# B-NAME_STUDENT\n",
    "# I-NAME_STUDENT\n",
    "# B-URL_PERSONAL\n",
    "\n",
    "B_name = [beginning_labels['B-NAME_STUDENT'],\n",
    "        middle_labels['B-NAME_STUDENT'],\n",
    "        end_labels['B-NAME_STUDENT']]\n",
    "\n",
    "I_name = [beginning_labels['I-NAME_STUDENT'],\n",
    "        middle_labels['I-NAME_STUDENT'],\n",
    "        end_labels['I-NAME_STUDENT']]\n",
    "\n",
    "B_url = [beginning_labels['B-URL_PERSONAL'],\n",
    "        middle_labels['B-URL_PERSONAL'],\n",
    "        end_labels['B-URL_PERSONAL']]\n",
    "\n",
    "locations = ['Beginning', 'Middle', 'End']\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "fig.suptitle('Frequency of most popular labels at different positions in the text')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].bar(locations, B_name)\n",
    "ax[0].set_title('B-Name')\n",
    "ax[1].bar(locations, I_name)\n",
    "ax[1].set_title('I-Name')\n",
    "ax[2].bar(locations, B_url)\n",
    "ax[2].set_title('B-URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0cb9b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.356941200Z"
    }
   },
   "outputs": [],
   "source": [
    "c_pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ed9b3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.361435200Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(c.keys())}\n",
    "ids_to_labels = {v: k for v, k in enumerate(c.keys())}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed8113",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "First we scoured the data to find the usuable text with our pretrained model with Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c4faa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.364757300Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = re.compile('\\xa0|\\uf0b7|\\u200b')\n",
    "df.loc[:,'full_text'] = df.loc[:,'full_text'].replace(pattern, ' ')\n",
    "df.loc[:,'tokens'] = df.loc[:,'tokens'].apply(lambda line: [tok for tok in line if not re.search(pattern,tok)])\n",
    "\n",
    "df_usable = df.iloc[df[~(df.tokens.apply(len) != df.labels.apply(len))].index]\n",
    "1-(len(df_usable))/len(df.document)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_usable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.368069200Z"
    }
   },
   "id": "b5a674f8d5d5bf30",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4723c782",
   "metadata": {},
   "source": [
    "We created a function to tokenize and label all of the lines in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48777ea2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.371546Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_smaller_inputs(dataframe):\n",
    "    df_out = pd.DataFrame(columns = ['tokens','labels','document','document_location'])\n",
    "    idx_df = 0\n",
    "    max_len = config['MAX_LEN']\n",
    "    \n",
    "    for _,line in dataframe.iterrows():\n",
    "        location_counter = 0\n",
    "        tokens = line.tokens\n",
    "        labels = line.labels\n",
    "        document = line.document\n",
    "        items = range(0,len(tokens),max_len)\n",
    "        \n",
    "        for i in items:\n",
    "            df_out.at[idx_df,'tokens'] = tokens[i:i+max_len]\n",
    "            df_out.at[idx_df,'labels'] = labels[i:i+max_len]\n",
    "            df_out.at[idx_df,'document'] = document\n",
    "            df_out.at[idx_df,'document_location'] = location_counter\n",
    "            location_counter += 1\n",
    "            idx_df += 1\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73aaea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.374959500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_model_input = make_smaller_inputs(df_usable)\n",
    "df_model_input.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b8c02",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.377280400Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_model_input.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e261b43",
   "metadata": {},
   "source": [
    "### Creating the training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb6f0e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.380794800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_model_input, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e1958",
   "metadata": {},
   "source": [
    "### Formatting split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b1ca2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.384238900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.reset_index(drop = True, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178fadd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.388737500Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.reset_index(drop = True, inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e75cd",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iteration 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a31ae15f3cb298"
  },
  {
   "cell_type": "markdown",
   "id": "8b652f99",
   "metadata": {},
   "source": [
    "adapted from \n",
    "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb#scrollTo=Eh3ckSO0YMZW"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenizer and Label allignment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8186275db5c43be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61724112",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.393211300Z"
    }
   },
   "outputs": [],
   "source": [
    "# class dataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, max_len):\n",
    "#         self.len = len(dataframe)\n",
    "#         self.data = dataframe\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # step 1: get the sentence and word labels \n",
    "#         tokens = self.data.tokens[index]\n",
    "#         word_labels = self.data.labels[index]\n",
    "\n",
    "#         # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "#         # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "#         encoding = self.tokenizer(tokens,\n",
    "#                                   is_split_into_words=True,\n",
    "#                                   return_offsets_mapping=True,\n",
    "#                                   padding='max_length',\n",
    "#                                   truncation=True,\n",
    "#                                   max_length=self.max_len)\n",
    "\n",
    "#         # step 3: create token labels only for first word pieces of each tokenized word\n",
    "#         labels = [ labels_to_ids[label] for label in word_labels]\n",
    "#         # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "#         # create an empty array of -100 of length max_length\n",
    "#         encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "#         # set only labels whose first offset position is 0 and the second is not 0\n",
    "#         i = 0\n",
    "#         for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "#             if mapping[0] == 0 and mapping[1] != 0:\n",
    "#                 # overwrite label\n",
    "#                 encoded_labels[idx] = labels[i]\n",
    "#                 i += 1\n",
    "\n",
    "#         # step 4: turn everything into PyTorch tensors\n",
    "#         item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "#         item['labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "# training_set = dataset(df_train, config['tokenizer'], config['MAX_LEN'])\n",
    "# testing_set = dataset(df_test, config['tokenizer'], config['MAX_LEN'])\n",
    "# training_set[2][\"input_ids\"].unsqueeze(0)\n",
    "# for token, label in zip(config['tokenizer'].convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "#     print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb12963",
   "metadata": {},
   "source": [
    "Setting training and testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6594a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.396732500Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_params = {'batch_size': config[\"TRAIN_BATCH_SIZE\"],\n",
    "#                 'shuffle': True,\n",
    "#                 'num_workers': 0\n",
    "#                 }\n",
    "\n",
    "# test_params = {'batch_size': config[\"VALID_BATCH_SIZE\"],\n",
    "#                'shuffle': True,\n",
    "#                'num_workers': 0\n",
    "#                }\n",
    "\n",
    "# training_loader = DataLoader(training_set, **train_params)\n",
    "# testing_loader = DataLoader(testing_set, **test_params)\n",
    "# model = BertForTokenClassification.from_pretrained(config['pretrained_model'], num_labels=len(labels_to_ids))\n",
    "# model.to(config['device'])\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b92d9eb89bf098fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701039e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.401227800Z"
    }
   },
   "outputs": [],
   "source": [
    "### Training\n",
    "# # Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "# def train(epoch):\n",
    "#     tr_loss, tr_accuracy = 0, 0\n",
    "#     nb_tr_examples, nb_tr_steps = 0, 0\n",
    "#     tr_preds, tr_labels = [], []\n",
    "#     # put model in training mode\n",
    "#     model.train()\n",
    "# \n",
    "#     for idx, batch in enumerate(training_loader):\n",
    "# \n",
    "#         ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "#         mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "#         labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "# \n",
    "#         outputs = model(input_ids=ids.long(), attention_mask=mask.long(), labels=labels.long())\n",
    "#         loss = outputs[0]\n",
    "#         tr_logits = outputs[1]\n",
    "#         tr_loss += loss.item()\n",
    "# \n",
    "#         nb_tr_steps += 1\n",
    "#         nb_tr_examples += labels.size(0)\n",
    "# \n",
    "#         if idx % 100==0:\n",
    "#             loss_step = tr_loss/nb_tr_steps\n",
    "#             print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "# \n",
    "#         # compute training accuracy\n",
    "#         flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "#         active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "#         flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "#         \n",
    "#         # only compute accuracy at active labels\n",
    "#         active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "#         #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "# \n",
    "#         labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "#         predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "# \n",
    "#         tr_labels.extend(labels)\n",
    "#         tr_preds.extend(predictions)\n",
    "# \n",
    "#         tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "#         tr_accuracy += tmp_tr_accuracy\n",
    "# \n",
    "#         # gradient clipping\n",
    "#         torch.nn.utils.clip_grad_norm_(\n",
    "#             parameters=model.parameters(), max_norm=config['MAX_GRAD_NORM']\n",
    "#         )\n",
    "# \n",
    "#         # backward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# \n",
    "#     epoch_loss = tr_loss / nb_tr_steps\n",
    "#     tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "#     print(f\"Training loss epoch: {epoch_loss}\")\n",
    "#     print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "# run = False\n",
    "# if run:\n",
    "#     for epoch in range(config['EPOCHS']):\n",
    "#         print(f\"Training epoch: {epoch + 1}\")\n",
    "#         train(epoch)\n",
    "#     run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training epoch: 1\n",
    "Training loss epoch: 0.007183262327166176\n",
    "Training accuracy epoch: 0.9988009906964034\n",
    "\n",
    "Execution Time: 2h 33m 45s\n",
    "Batch Size: 2\n",
    "LR: 1e-5\n",
    "Optimizer: Adam"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0a1afce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53a534405be188c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ab661",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.404613100Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# directory = config['model_path']\n",
    "\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# # save vocabulary of the tokenizer\n",
    "# config['tokenizer'].save_vocabulary(directory)\n",
    "# # save the model weights and its configuration file\n",
    "# save_model = True\n",
    "# if save_model:  \n",
    "#     model.save_pretrained(directory)\n",
    "#     print('All files saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b30d5eacc9f489f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8c36b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.409178700Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_1 = BertForTokenClassification.from_pretrained(config['model_path'], num_labels=len(labels_to_ids))\n",
    "# model_1.to(config['device'])\n",
    "# # def valid(model, testing_loader):\n",
    "#     # put model in evaluation mode\n",
    "#     model.eval()\n",
    "    \n",
    "#     eval_loss, eval_accuracy = 0, 0\n",
    "#     nb_eval_examples, nb_eval_steps = 0, 0\n",
    "#     eval_preds, eval_labels = [], []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "#             ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n",
    "#             mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n",
    "#             labels = batch['labels'].to(config['device'], dtype = torch.long)\n",
    "\n",
    "#             outputs = model(input_ids=ids.long(), attention_mask=mask.long(), labels=labels.long())\n",
    "            \n",
    "#             loss = outputs[0]\n",
    "#             eval_logits = outputs[1]\n",
    "#             eval_loss += loss.item()\n",
    "            \n",
    "#             nb_eval_steps += 1\n",
    "#             nb_eval_examples += labels.size(0)\n",
    "        \n",
    "#             if idx % 100==0:\n",
    "#                 loss_step = eval_loss/nb_eval_steps\n",
    "#                 print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "            \n",
    "#             # compute evaluation accuracy\n",
    "#             flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "#             active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "#             flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "#             # only compute accuracy at active labels\n",
    "#             active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "#             labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "#             predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "#             eval_labels.extend(labels)\n",
    "#             eval_preds.extend(predictions)\n",
    "            \n",
    "#             tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "#             eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "#     labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "#     predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "#     eval_loss = eval_loss / nb_eval_steps\n",
    "#     eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "#     print(f\"Validation Loss: {eval_loss}\")\n",
    "#     print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "#     return labels, predictions\n",
    "\n",
    "# labels, predictions = valid(model_1, testing_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e418a8e",
   "metadata": {},
   "source": [
    "Validation Loss: 0.0025191350434306515\n",
    "Validation Accuracy: 0.9994422838479019\n",
    "Execution Time: 08m 07.238s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93cf4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.413685900Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb51181",
   "metadata": {},
   "source": [
    "About 50% for getting student names correct, 0% for the others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e42de",
   "metadata": {},
   "source": [
    "## Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08916e",
   "metadata": {},
   "source": [
    "Updating the tokenizer to properly create context between the words and the PII labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269645e4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.417050600Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tokenize(df, tokenizer):\n",
    "#     text = []\n",
    "#     token_map = []\n",
    "#     \n",
    "#     idx = 0\n",
    "#     \n",
    "#     for t, ws in zip(df[\"tokens\"], df[\"trailing_whitespace\"]):\n",
    "#         \n",
    "#         text.append(t)\n",
    "#         token_map.extend([idx]*len(t))\n",
    "#         if ws:\n",
    "#             text.append(\" \")\n",
    "#             token_map.append(-1)\n",
    "#             \n",
    "#         idx += 1\n",
    "#         \n",
    "#         \n",
    "#     tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=False)\n",
    "#     \n",
    "#         \n",
    "#     return {\n",
    "#         **tokenized,\n",
    "#         \"token_map\": token_map,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LOOK AT ME FROM HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77b6a40bf91c561c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenizer and Label allignment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d921b549820af97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize(line, tokenizer):\n",
    "    # step 1: get the sentence and word labels \n",
    "    tokens = line.tokens\n",
    "    word_labels = line.labels\n",
    "    document = line.document\n",
    "    location = line.document_location\n",
    "    # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "    # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "    encoding = tokenizer(tokens,\n",
    "                              is_split_into_words=True,\n",
    "                              return_offsets_mapping=True,\n",
    "                              padding='max_length',\n",
    "                              max_length=2 * config['MAX_LEN']\n",
    "                              )\n",
    "    temp_list = [0 for _ in range(2 * config['MAX_LEN'] - len(word_labels))]\n",
    "    labels = [labels_to_ids[label] for label in word_labels] + temp_list\n",
    "    \n",
    "    encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * 0\n",
    "    # WORKS\n",
    "    i = 0\n",
    "    for idx, mapping in enumerate(encoding[\"offset_mapping\"]):        \n",
    "        if mapping[0] == 0:\n",
    "            i += 1\n",
    "    # step 4: turn everything into PyTorch tensors\n",
    "    item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "            \n",
    "    item['labels'] = torch.as_tensor(encoded_labels)\n",
    "    # print(items) TODO\n",
    "    return {'item': item, 'document': document, 'location': location}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.420420600Z"
    }
   },
   "id": "1b774fb5edd48d94",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b8fa378",
   "metadata": {},
   "source": [
    "Create the mappings for the tokenized text, calling the tokenizer function above. This will store all of the values in separate lists that we will be able to call for the output function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae3edf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.423895100Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a0935900bcc79",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.428253500Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"cleaned_train.json\", \"w\") as data_file:\n",
    "#     data_file.write(df_train.to_json())\n",
    "#     data_file.close()\n",
    "\n",
    "# with open(\"cleaned_train.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# with open(\"../datasets/Official/train.json\", \"r\") as f:\n",
    "#   data = json.load(f)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "# ds = Dataset.from_dict({\n",
    "#     # \"full_text\": [x[\"full_text\"] for x in data],\n",
    "#     \"labels\": data[\"labels\"],\n",
    "#     \"tokens\": data[\"tokens\"],\n",
    "#     # \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "# })\n",
    "\n",
    "\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(config['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset_temp = df_train.apply(lambda line: tokenize(line, config['tokenizer']), axis = 1).to_list()\n",
    "train_dataset = pd.DataFrame.from_dict(train_dataset_temp, orient = 'columns')\n",
    "train_dataset.head()"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.430678400Z"
    }
   },
   "id": "73a98607",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predict_dataset_temp = df_test.apply(lambda line: tokenize(line, config['tokenizer']), axis = 1).to_list()\n",
    "predict_dataset = pd.DataFrame.from_dict(predict_dataset_temp, orient = 'columns')\n",
    "predict_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.432909600Z"
    }
   },
   "id": "e31f450ea4c339c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_dataset = predict_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.448967800Z"
    }
   },
   "id": "23acbe1899917b72"
  },
  {
   "cell_type": "markdown",
   "id": "66d01ba3",
   "metadata": {},
   "source": [
    "Create the new training class, with the model creation leveraging AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5cfdcf604675a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # # Remove ignored index (special tokens)\n",
    "    # true_predictions = [\n",
    "    #     [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #     for prediction, label in zip(predictions, labels)\n",
    "    # ]\n",
    "    # true_labels = [\n",
    "    #     [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #     for prediction, label in zip(predictions, labels)\n",
    "    # ]\n",
    "\n",
    "    results = metric.compute(predictions=predictions, references=labels)\n",
    "    if data_args.return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.448967800Z"
    }
   },
   "id": "e165ae17c3a1047",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained(config['pretrained_model'])\n",
    "data_collator = DataCollatorForTokenClassification(config['tokenizer'])\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=config['LEARNING_RATE'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.450184Z"
    }
   },
   "id": "59845db44cc566d3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea78549b1faff0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.450184Z"
    }
   },
   "id": "3cea82d72c9160cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= config['model_path'],\n",
    "    overwrite_output_dir = True,\n",
    "    do_train = True,\n",
    "    do_predict = False,\n",
    "    do_eval = True,\n",
    "    per_device_eval_batch_size=1, \n",
    "    report_to=\"none\",\n",
    "    num_train_epochs = config['EPOCHS'],\n",
    "    learning_rate = config['LEARNING_RATE'],\n",
    "    save_strategy = 'epoch',\n",
    "    disable_tqdm= True,\n",
    "    no_cude = False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = train_dataset.item,\n",
    "    eval_dataset = train_dataset.item,\n",
    "    # predict_dataset = predict_dataset.item,\n",
    "    # tokenizer=config['tokenizer'],\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.450184Z"
    }
   },
   "id": "daf9b24c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we call the actual training function that will supply the model created above with the information that it needs to create context between text, and the labels. It will work out which values match the closes and assign the proper label to it, based on how well that label matches the value."
   ],
   "metadata": {},
   "id": "c93b65d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://github.com/huggingface/transformers/blob/main/examples/pytorch/token-classification/run_ner.py#L546"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d18ec7557129e12"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    train_result = trainer.train()\n",
    "    metrics = train_result.metrics\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    # max_train_samples = (\n",
    "    #     data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    # )\n",
    "    metrics[\"train_samples\"] = len(train_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    # trainer.save_state()\n",
    "model = BertForTokenClassification.from_pretrained(config['model_path'], num_labels=len(labels_to_ids))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.450184Z"
    }
   },
   "id": "b4987feca6d0ebf7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# if training_args.do_eval:\n",
    "#     logger.info(\"*** Evaluate ***\")\n",
    "# \n",
    "#     metrics = trainer.evaluate()\n",
    "# \n",
    "#  #   max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\n",
    "#     metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "# \n",
    "#     trainer.log_metrics(\"eval\", metrics)\n",
    "#     trainer.save_metrics(\"eval\", metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.452422100Z"
    }
   },
   "id": "7ae7c454ca3d541"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6699fc4bbad759"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predict\n",
    "if training_args.do_predict:\n",
    "    # logger.info(\"*** Predict ***\")\n",
    "\n",
    "    predictions, labels, metrics = trainer.predict(predict_dataset, metric_key_prefix=\"predict\")\n",
    "    # predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # # Remove ignored index (special tokens)\n",
    "    # true_predictions = [\n",
    "    #     [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #     for prediction, label in zip(predictions, labels)\n",
    "    # ]\n",
    "\n",
    "    trainer.log_metrics(\"predict\", metrics)\n",
    "    trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "    # Save predictions\n",
    "    # output_predictions_file = os.path.join(training_args.output_dir, \"predictions.txt\")\n",
    "    # if trainer.is_world_process_zero():\n",
    "    #     with open(output_predictions_file, \"w\") as writer:\n",
    "    #         for prediction in true_predictions:\n",
    "    #             writer.write(\" \".join(prediction) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:42.454624500Z"
    }
   },
   "id": "bd42ad6441d1755f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TO HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca5aff748cd39b2"
  },
  {
   "cell_type": "markdown",
   "id": "440f6cbb",
   "metadata": {},
   "source": [
    "Create the lists, pulling the context of the list. This will look at the token_map and place the proper label in it's own list, which is associated with the index of the corresponding item in the other list.\n",
    "\n",
    "It ensures that we are ignoring the o labels so that we don't report those in our created file."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# predictions = trainer.predict(ds).predictions\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m preds_temp \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[43mpredictions\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m id2label \u001B[38;5;241m=\u001B[39m ids_to_labels\n",
      "\u001B[1;31mNameError\u001B[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# predictions = trainer.predict(ds).predictions\n",
    "preds_temp = np.argmax(predictions, axis=2)\n",
    "# pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n",
    "id2label = ids_to_labels\n",
    "# preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n",
    "# O_preds = pred_softmax[:,:,12]\n",
    "preds_temp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:43.725187300Z",
     "start_time": "2024-04-18T01:10:42.818494400Z"
    }
   },
   "id": "56aa5d8b5a00434b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# preds_final = np.where(O_preds < config['threshold'], preds_without_O , preds)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# preds_final = predictions.argmax(-1)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mpreds_final\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "# preds_final = np.where(O_preds < config['threshold'], preds_without_O , preds)\n",
    "# preds_final = predictions.argmax(-1)\n",
    "preds_final"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-18T01:10:43.711355300Z"
    }
   },
   "id": "f38be273",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a328a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:43.929807700Z",
     "start_time": "2024-04-18T01:10:43.791726700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[0;32m      2\u001B[0m document, token, label, token_str \u001B[38;5;241m=\u001B[39m [], [], [], []\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p, token_map, offsets, tokens, doc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[43mpreds_final\u001B[49m, ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_map\u001B[39m\u001B[38;5;124m\"\u001B[39m], ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moffset_mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m], ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m\"\u001B[39m], ds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdocument\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m token_pred, (start_idx, end_idx) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(p, offsets):\n\u001B[0;32m      6\u001B[0m         label_pred \u001B[38;5;241m=\u001B[39m id2label[\u001B[38;5;28mstr\u001B[39m(token_pred)]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preds_final' is not defined"
     ]
    }
   ],
   "source": [
    "pairs = set()\n",
    "document, token, label, token_str = [], [], [], []\n",
    "for p, token_map, offsets, tokens, doc in zip(preds_final, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n",
    "\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]\n",
    "\n",
    "        if start_idx + end_idx == 0: \n",
    "            continue\n",
    "\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "\n",
    "        # ignore \"\\n\\n\"\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        if start_idx >= len(token_map): \n",
    "            break\n",
    "\n",
    "        token_id = token_map[start_idx]\n",
    "\n",
    "        # ignore \"O\" predictions and whitespace preds\n",
    "        if label_pred == \"O\" or token_id == -1:\n",
    "            continue\n",
    "            \n",
    "        pair = (doc, token_id)\n",
    "\n",
    "        if pair in pairs:\n",
    "            continue\n",
    "            \n",
    "        document.append(doc)\n",
    "        token.append(token_id)\n",
    "        label.append(label_pred)\n",
    "        token_str.append(tokens[token_id])\n",
    "        pairs.add(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4e0f6",
   "metadata": {},
   "source": [
    "This next part is creating the submission file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837ac4db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:43.948740400Z",
     "start_time": "2024-04-18T01:10:43.906232100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [document, token, label, token_str, row_id]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>token</th>\n      <th>label</th>\n      <th>token_str</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = pd.DataFrame({\n",
    "    \"document\": document,\n",
    "    \"token\": token,\n",
    "    \"label\": label,\n",
    "    \"token_str\": token_str\n",
    "})\n",
    "df_result[\"row_id\"] = list(range(len(df_result)))\n",
    "display(df_result.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7773da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T01:10:44.074576600Z",
     "start_time": "2024-04-18T01:10:43.944451900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [row_id, document, token, label]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>document</th>\n      <th>token</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = df_result[['row_id', 'document', 'token', 'label']]\n",
    "display(df_result.head(100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
